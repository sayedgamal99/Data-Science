{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH11 Training Deep Neural Networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activations and he initializations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = tf.keras.layers.Dense(\n",
    "    50, activation='relu', kernel_initializer='he_normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'truncated_normal'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense.kernel_initializer.distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_avg_init = tf.keras.initializers.VarianceScaling(scale=2., mode=\"fan_avg\",\n",
    "                                                    distribution=\"uniform\")\n",
    "dense = tf.keras.layers.Dense(50, activation=\"sigmoid\",\n",
    "                              kernel_initializer=he_avg_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "leaky relu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaky_relu = tf.keras.layers.LeakyReLU(alpha=.2)\n",
    "dense = tf.keras.layers.Dense(\n",
    "    50, activation=leaky_relu, kernel_initializer='he_normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "elu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = tf.keras.layers.Dense(\n",
    "    50, activation='elu', kernel_initializer='he_normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SELU` , but it has few considerations:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• The input features must be standardized: mean 0 and standard deviation 1.\n",
    "\n",
    "• Every hidden layer’s weights must be initialized using LeCun normal initializa\n",
    "tion. In Keras, this means setting kernel_initializer=\"lecun_normal\".\n",
    "\n",
    "• The self-normalizing property is only guaranteed with plain MLPs.\n",
    "\n",
    "• You cannot use regularization techniques like ℓ1\n",
    "or ℓ2\n",
    "regularization, max-norm,\n",
    "batch-norm, or regular dropout.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = tf.keras.layers.Dense(\n",
    "    50, activation='selu', kernel_initializer='lecun_normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "an example of a self-regularized network using SELU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for i in range(100):\n",
    "    model.add(tf.keras.layers.Dense(100, activation='selu',\n",
    "              kernel_initializer='lecun_normal'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.SGD(\n",
    "    learning_rate=0.001), metrics=['accuracy'])\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]\n",
    "X_train, X_valid, X_test = X_train / 255, X_valid / 255, X_test / 255\n",
    "\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
    "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
    "X_train_scaled = (X_train - pixel_means)/pixel_stds\n",
    "X_valid_scaled = (X_valid - pixel_means)/pixel_stds\n",
    "X_test_scaled = (X_test - pixel_means)/pixel_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1719/1719 [==============================] - 36s 18ms/step - loss: 1.0050 - accuracy: 0.6275 - val_loss: 0.7212 - val_accuracy: 0.7350\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 33s 19ms/step - loss: 0.6421 - accuracy: 0.7656 - val_loss: 0.5779 - val_accuracy: 0.7892\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 32s 19ms/step - loss: 0.5580 - accuracy: 0.7990 - val_loss: 0.5336 - val_accuracy: 0.8102\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 30s 18ms/step - loss: 0.5159 - accuracy: 0.8169 - val_loss: 0.4961 - val_accuracy: 0.8254\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 33s 19ms/step - loss: 0.4952 - accuracy: 0.8280 - val_loss: 0.4968 - val_accuracy: 0.8308\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=5,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network managed to learn, despite how deep it is. Now look at what happens if we try to use the ReLU activation function instead:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for layer in range(100):\n",
    "    model.add(tf.keras.layers.Dense(100, activation=\"relu\",\n",
    "                                    kernel_initializer=\"he_normal\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1719/1719 [==============================] - 34s 18ms/step - loss: 1.9997 - accuracy: 0.2147 - val_loss: 1.7337 - val_accuracy: 0.3048\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 30s 17ms/step - loss: 1.2544 - accuracy: 0.4702 - val_loss: 1.3963 - val_accuracy: 0.3952\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 31s 18ms/step - loss: 1.0043 - accuracy: 0.5888 - val_loss: 1.6453 - val_accuracy: 0.3570\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 31s 18ms/step - loss: 0.9494 - accuracy: 0.6116 - val_loss: 0.7680 - val_accuracy: 0.7068\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 31s 18ms/step - loss: 0.8271 - accuracy: 0.6733 - val_loss: 0.7861 - val_accuracy: 0.6828\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=5,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not great at all, we suffered from the vanishing/exploding gradients problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GELU, Swish and Mish\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mish(x):\n",
    "    return x * tf.math.tanh(tf.math.softplus(x))\n",
    "\n",
    "\n",
    "# Using GELU activation\n",
    "dense_gelu = tf.keras.layers.Dense(\n",
    "    50, activation=tf.keras.activations.gelu, kernel_initializer='he_normal')\n",
    "\n",
    "# Using built-in Swish activation\n",
    "dense_swish = tf.keras.layers.Dense(\n",
    "    50, activation='swish', kernel_initializer='he_normal')\n",
    "\n",
    "# Using Mish activation\n",
    "dense_mish = tf.keras.layers.Dense(\n",
    "    50, activation=mish, kernel_initializer='he_normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten, Dense, BatchNormalization\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    Flatten(input_shape=[28, 28]),\n",
    "    BatchNormalization(),\n",
    "    Dense(300, activation='relu', kernel_initializer='he_normal'),\n",
    "    BatchNormalization(),\n",
    "    Dense(100, activation='relu', kernel_initializer='he_normal'),\n",
    "    BatchNormalization(),\n",
    "    Dense(10, activation='softmax'),\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 784)              3136      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 300)              1200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(var.name, var.trainable) for var in model.layers[1].variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1719/1719 [==============================] - 10s 5ms/step - loss: 0.5548 - accuracy: 0.8077 - val_loss: 0.3976 - val_accuracy: 0.8580\n",
      "Epoch 2/2\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4069 - accuracy: 0.8550 - val_loss: 0.3608 - val_accuracy: 0.8686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d70fb05db0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\",\n",
    "              metrics=\"accuracy\")\n",
    "model.fit(X_train, y_train, epochs=2, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes applying BN before the activation function works better (there's a debate on this topic). Moreover, the layer before a BatchNormalization layer does not need to have bias terms, since the BatchNormalization layer some as well, it would be a waste of parameters, so you can set use_bias=False when creating those layers:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.6099 - accuracy: 0.7979 - val_loss: 0.4347 - val_accuracy: 0.8442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d70fb04c40>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Activation\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=[28, 28]),\n",
    "    Dense(300, kernel_initializer='he_normal'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Dense(100, kernel_initializer='he_normal'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\",\n",
    "              metrics=\"accuracy\")\n",
    "model.fit(X_train, y_train, epochs=1, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Clipping\n",
    "\n",
    "to avoid gradients explosion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All tf.keras.optimizers accept clipnorm or clipvalue arguments:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = tf.keras.optimizers.SGD(clipvalue=1.0)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = tf.keras.optimizers.SGD(clipnorm=1.0)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
