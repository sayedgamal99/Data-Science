{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CH13 Exercises: Loading and Preprocessing Data With Tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 9. Load the Fashion MNIST dataset:(introduced in Chapter 10);\n",
    "\n",
    "  - split it into a training set, a validation set, and a test set; shuffle the training set; and save each dataset to multiple TFRecord files.\n",
    "\n",
    "  - Each record should be a serialized Example protobuf with two features: the serialized image (use tf.io.serialize_tensor() to serialize each image), and the label.\n",
    "\n",
    "  - Then use tf.data to create an efficient dataset for each set.\n",
    "\n",
    "  - Finally, use a Keras model to train these datasets, including a preprocessing layer to standardize each input feature. Try to make the input pipeline as efficient as possible, using TensorBoard to visualize profiling data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- loading the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets.fashion_mnist import load_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55000, 28, 28), (5000,), (10000, 28, 28), array([9, 0, 0], dtype=uint8))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_valid.shape, X_test.shape, y_valid[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = X_train[0]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Length:  55000\n",
      "Valid Length:  5000\n",
      "Test Length:  10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<_ShuffleDataset element_spec=(TensorSpec(shape=(28, 28), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.uint8, name=None))>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train,y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(X_train),seed=42)\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((X_valid,y_valid))\n",
    "test_dataset =  tf.data.Dataset.from_tensor_slices((X_test,y_test))\n",
    "\n",
    "print('Train Data Length: ', len(train_dataset))\n",
    "print('Valid Length: ',len(valid_dataset))\n",
    "print('Test Length: ', len(test_dataset))\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's save each dataset into multiple tfrecord files, for example 10 files for each data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([28, 28])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5500"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "55000//10 + 55000%10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_file0 file saved successfully\n",
      "train_file1 file saved successfully\n",
      "train_file2 file saved successfully\n",
      "train_file3 file saved successfully\n",
      "train_file4 file saved successfully\n",
      "train_file5 file saved successfully\n",
      "train_file6 file saved successfully\n",
      "train_file7 file saved successfully\n",
      "train_file8 file saved successfully\n",
      "train_file9 file saved successfully\n",
      "==================================================\n",
      "Train files finished.\n",
      " --------------------------------------------------\n",
      "valid_file0 file saved successfully\n",
      "valid_file1 file saved successfully\n",
      "valid_file2 file saved successfully\n",
      "valid_file3 file saved successfully\n",
      "valid_file4 file saved successfully\n",
      "valid_file5 file saved successfully\n",
      "valid_file6 file saved successfully\n",
      "valid_file7 file saved successfully\n",
      "valid_file8 file saved successfully\n",
      "valid_file9 file saved successfully\n",
      "==================================================\n",
      "Valid files finished.\n",
      " --------------------------------------------------\n",
      "test_file0 file saved successfully\n",
      "test_file1 file saved successfully\n",
      "test_file2 file saved successfully\n",
      "test_file3 file saved successfully\n",
      "test_file4 file saved successfully\n",
      "test_file5 file saved successfully\n",
      "test_file6 file saved successfully\n",
      "test_file7 file saved successfully\n",
      "test_file8 file saved successfully\n",
      "test_file9 file saved successfully\n",
      "==================================================\n",
      "Test files finished.\n",
      " --------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.train import Example, Features, Feature, BytesList, Int64List\n",
    "\n",
    "def save_dataset_to_10_tfrecord(data_iter, length, the_type='Train'):\n",
    "    if the_type == 'Train':\n",
    "        name = 'train_file'\n",
    "    elif the_type == 'Valid':\n",
    "        name = 'valid_file'\n",
    "    else:\n",
    "        name = 'test_file'\n",
    "\n",
    "    for i in range(10):\n",
    "        with tf.io.TFRecordWriter(f'ignored/{name}{i+1}.tfrecord') as f:\n",
    "            for _ in range(length // 10):\n",
    "                try:\n",
    "                    img, label = next(data_iter)\n",
    "                    data = tf.io.encode_jpeg(img[..., tf.newaxis])\n",
    "                    example_with_image = Example(features=Features(feature={\n",
    "                        \"image\": Feature(bytes_list=BytesList(value=[data.numpy()])),  # Encoded image data\n",
    "                        \"label\": Feature(int64_list=Int64List(value=[label]))  # Label \n",
    "                    }))\n",
    "                    serialized_example = example_with_image.SerializeToString()\n",
    "                    f.write(serialized_example)\n",
    "                except StopIteration:\n",
    "                    print(\"Data iterator exhausted. Ending early.\")\n",
    "                    break  # Stop if there are no more data\n",
    "\n",
    "            print(f'{name}{i} file saved successfully')\n",
    "    \n",
    "    print('=' * 50)\n",
    "    print(f'{the_type} files finished.\\n','-'*50)\n",
    "\n",
    "\n",
    "save_dataset_to_10_tfrecord(iter(train_dataset),len(train_dataset), 'Train')\n",
    "save_dataset_to_10_tfrecord(iter(valid_dataset),len(valid_dataset), 'Valid')\n",
    "save_dataset_to_10_tfrecord(iter(test_dataset),len(test_dataset), 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok, we saved each dataset into 10 tfrecord files, now we try to read them again..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_descriptions = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64, default_value=-1)\n",
    "        }\n",
    "\n",
    "def parse(serialized_example):\n",
    "        example = tf.io.parse_single_example(serialized_example,feature_description)\n",
    "        image = tf.io.decode_jpeg(example[\"image\"].values[0])\n",
    "        image = tf.reshape(image, shape=[28,28])\n",
    "        return image, example[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 28, 28) (30,)\n",
      "tf.Tensor([6 6 2 7 0 7 3 3 2 7 9 6 2 3 3 6 2 9 2 4 3 9 0 1 1 1 6 4 6 1], shape=(30,), dtype=int64)\n",
      "(30, 28, 28) (30,)\n",
      "tf.Tensor([0 9 1 4 0 2 3 1 3 8 7 7 6 6 5 3 5 5 5 0 6 0 5 2 3 1 1 3 2 9], shape=(30,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for x,y in (tf.data.TFRecordDataset('ignored\\\\train_file5.tfrecord')).map(parse).batch(30).take(2):\n",
    "    print(x.shape, y.shape)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_ShuffleDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)> 10\n",
      "[b'ignored\\\\train_file5.tfrecord', b'ignored\\\\train_file9.tfrecord', b'ignored\\\\train_file6.tfrecord', b'ignored\\\\train_file4.tfrecord', b'ignored\\\\train_file7.tfrecord', b'ignored\\\\train_file10.tfrecord', b'ignored\\\\train_file2.tfrecord', b'ignored\\\\train_file8.tfrecord', b'ignored\\\\train_file3.tfrecord', b'ignored\\\\train_file1.tfrecord']\n"
     ]
    }
   ],
   "source": [
    "train_filepaths = 'ignored/train_file*.tfrecord'\n",
    "train_filepath_dataset = tf.data.Dataset.list_files(train_filepaths,seed=42)\n",
    "\n",
    "valid_filepaths = 'ignored/valid_file*.tfrecord'\n",
    "valid_filepath_dataset =  tf.data.Dataset.list_files(valid_filepaths,shuffle=False)\n",
    "\n",
    "test_filepaths = 'ignored/test_file*.tfrecord'\n",
    "test_filepath_dataset =  tf.data.Dataset.list_files(test_filepaths,shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "print(train_filepath_dataset, len(train_filepath_dataset))\n",
    "print(list(train_filepath_dataset.as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reading the data from files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reader(filepath_dataset, n_readers=10):\n",
    "    return filepath_dataset.interleave(num_parallel_calls=tf.data.AUTOTUNE,\n",
    "            map_func = lambda filepath: tf.data.TFRecordDataset(filepath).map(parse),\n",
    "            cycle_length=n_readers).cache().batch(32).prefetch(1)\n",
    "\n",
    "train_dataset = reader(train_filepath_dataset)\n",
    "valid_dataset = reader(valid_filepath_dataset)\n",
    "test_dataset = reader(test_filepath_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: (32, 28, 28), Label: (32,)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dataset.take(1):\n",
    "    print(f\"Input: {x.shape}, Label: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for X, y in valid_dataset.take(1):\n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(X[i].numpy(), cmap=\"binary\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(str(y[i].numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap Up:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image_batches = train_dataset.take(100).map(lambda image, label: image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3200, 28, 28)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(list(sample_image_batches.as_numpy_iterator()),\n",
    "                            axis=0).astype(np.float32).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "norm_layer = tf.keras.layers.Normalization(input_shape=[28, 28])\n",
    "\n",
    "sample_image_batches = train_dataset.take(100).map(lambda image, label: image)\n",
    "sample_images = np.concatenate(list(sample_image_batches.as_numpy_iterator()),\n",
    "                            axis=0).astype(np.float32)\n",
    "norm_layer.adapt(sample_images)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    norm_layer,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512,activation='leaky_relu'),\n",
    "    tf.keras.layers.Dense(128,activation='leaky_relu'),\n",
    "    tf.keras.layers.Dense(10,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_7 (Normaliza  (None, 28, 28)            57        \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 468931 (1.79 MB)\n",
      "Trainable params: 468874 (1.79 MB)\n",
      "Non-trainable params: 57 (232.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "            metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4623 - accuracy: 0.8320 - val_loss: 0.3827 - val_accuracy: 0.8618\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3587 - accuracy: 0.8674 - val_loss: 0.3733 - val_accuracy: 0.8712\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3192 - accuracy: 0.8808 - val_loss: 0.3770 - val_accuracy: 0.8696\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2942 - accuracy: 0.8904 - val_loss: 0.3776 - val_accuracy: 0.8782\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2755 - accuracy: 0.8967 - val_loss: 0.3970 - val_accuracy: 0.8760\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset,epochs=5,validation_data=valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "homl3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
