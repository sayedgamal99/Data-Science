{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fGtAg7QSBq_r"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-8IvGXjEHTS"
      },
      "source": [
        "### Tensors and Operations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abXFEq0TCVgd",
        "outputId": "67d306d9-493d-4fe8-a8d5-6bde9715d7ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "array([[1, 2, 3],\n",
              "       [4, 5, 6]])>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
        "t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtrxHqs6CDyE",
        "outputId": "5218c4c7-33d7-44c3-ab26-72f97f49f794"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([2, 3])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfPoBDoQCL6r",
        "outputId": "011f0136-4b2f-49c2-b9fb-40834784f7a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 2, 3],\n",
              "       [4, 5, 6]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOGZ3XpACa08",
        "outputId": "4076f570-f2af-433c-a2f8-5bb6bc421662"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor([3 6], shape=(2,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "print(t[0, 0])\n",
        "print(t[:, 2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW7yulK2CkWt",
        "outputId": "2bcd6aa9-9f88-4178-f1ee-aa8680dc948d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "array([[1, 2, 3],\n",
              "       [4, 5, 6]])>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t[..., :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75SMYYhxCr2n",
        "outputId": "7a069021-13e1-4de7-97d1-41fe24adf786"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 1), dtype=int32, numpy=\n",
              "array([[2],\n",
              "       [5]])>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t[..., 1, tf.newaxis]  # keep dimension 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBMU0W7vCvrH",
        "outputId": "b662b89b-4b70-461c-bf24-a3809acfb8ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "array([[11, 12, 13],\n",
              "       [14, 15, 16]])>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t+10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhIJaQ5NDC7B",
        "outputId": "1acf142a-ae62-4f6a-fd3a-2c2070f85481"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "array([[11, 12, 13],\n",
              "       [14, 15, 16]])>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.__add__(10)  # not in-place"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2qCPPCnDIr5",
        "outputId": "f47b9c7f-b456-41f7-9790-a8e37a683ff0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "array([[1, 2, 3],\n",
              "       [4, 5, 6]])>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3H74DoKDJOp",
        "outputId": "bb5cd6f5-3c0d-40ef-d09a-63cd3998ab7e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "array([[ 1,  4,  9],\n",
              "       [16, 25, 36]])>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.square(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czcO0XNGDT0q",
        "outputId": "84d0b8d6-1e09-47e3-afa2-31171c00b516"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[14, 32],\n",
              "       [32, 77]])>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t @ tf.transpose(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdSHOi0IEJZy"
      },
      "source": [
        "### Tensors and NumPy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "XK4z68RIDYHL"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cpl4hUOnDo4m",
        "outputId": "4157ccee-8349-448e-f6b9-bc574b753e7b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = np.array([2., 4., 5.])\n",
        "tf.constant(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiR6xyc-DsIu",
        "outputId": "1b52a024-a775-473a-e752-3b679aa578dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 4., 16., 25.])>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.square(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q25m4wqUD2l-",
        "outputId": "cf272777-c97f-4af7-97f8-8e2412d9bfbf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 1,  4,  9],\n",
              "       [16, 25, 36]])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.square(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dsh752mDEBgI"
      },
      "source": [
        "### Type Conversions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bcgeno05D9Av",
        "outputId": "e0ae7029-8c30-431e-8ee8-cc2632e9d998"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2] name: \n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    tf.constant(2.0) + tf.constant(40)\n",
        "except tf.errors.InvalidArgumentError as ex:\n",
        "    print(ex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTukCIaRERAE",
        "outputId": "4cdb38e2-5a4a-45f6-874f-461e60aa429f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:AddV2] name: \n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    tf.constant(2.0) + tf.constant(40., dtype=tf.float64)\n",
        "except tf.errors.InvalidArgumentError as ex:\n",
        "    # defualt values in tensorflow are float32, cannot manipulated with float64\n",
        "    print(ex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isV2hM-eEXEr",
        "outputId": "848170b9-29b1-42a3-ef5a-6d58e2f6dca4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=52.0>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.constant(2.) + tf.constant(50, dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AWQrWY7EZZD",
        "outputId": "36a67bd8-0aee-47f4-a9e7-962a50557903"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t2 = tf.constant(40, dtype=tf.float64)\n",
        "tf.constant(2.) + tf.cast(t2, tf.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-ClwN2VEypv"
      },
      "source": [
        "### Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfqKM28PEqjd",
        "outputId": "7312ae39-2d8d-41f6-85e4-cab9ffc1b5b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
              "array([[1., 2., 3.],\n",
              "       [4., 5., 6.]], dtype=float32)>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])\n",
        "v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGxDnKMIE4bX",
        "outputId": "d8d8804f-0369-4a52-948a-217acac64138"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
              "array([[ 2.,  4.,  6.],\n",
              "       [ 8., 10., 12.]], dtype=float32)>"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v.assign(2*v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riLfpqFJFAoH",
        "outputId": "6847fd80-f7e6-4ac9-b050-9a8afa858f06"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
              "array([[ 2.,  4.,  6.],\n",
              "       [ 8., 10., 12.]], dtype=float32)>"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op2QQS7mFBzo",
        "outputId": "3faf6d78-bbde-4ce8-90af-a44f76d63077"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
              "array([[42.,  4.,  6.],\n",
              "       [ 8., 10., 12.]], dtype=float32)>"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v[0, 0].assign(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RASTIl7sFF_g",
        "outputId": "0d41726a-d1e3-456f-ba89-f4de384489cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
              "array([[100.,   4.,   6.],\n",
              "       [400.,  10.,  12.]], dtype=float32)>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v.scatter_nd_update(indices=[[0, 0], [1, 0]], updates=[100, 400])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vtVimYKHDd3",
        "outputId": "4ca2ee01-d1cd-4da2-e59a-61dde0eb68e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    t[1] = [7., 8., 9.]  # cannot update with direct assignment\n",
        "except TypeError as ex:\n",
        "    print(ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custom Loss Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "def huber_fn(y_true, y_pred):\n",
        "    \"\"\"combine MSE smoothing property (at small values) and MAE outliers robustness property (at large values)\"\"\"\n",
        "    error = abs(y_true-y_pred)\n",
        "    squared = tf.square(error) / 2  # smoothing gradients factor\n",
        "    # -.5 for connection guaranteed between two losses at the threshold (1 here)\n",
        "    linear = error - .5\n",
        "    return tf.where(error < 1, squared, linear)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\sayed\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_valid_scaled = scaler.transform(X_valid)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "input_shape = X_train.shape[1:]\n",
        "\n",
        "tf.keras.utils.set_random_seed(42)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                          input_shape=input_shape),\n",
        "    tf.keras.layers.Dense(1),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7494 - mae: 1.1371 - val_loss: 0.3474 - val_mae: 0.6522\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - loss: 0.2607 - mae: 0.5681 - val_loss: 0.2553 - val_mae: 0.5383\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x15d452d4280>"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(loss=huber_fn, metrics=['mae'], optimizer='nadam')\n",
        "\n",
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Saving/Loading Models with Custom objects\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs('saved_models', exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('saved_models/my_model_with_custom_hyper_loss.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the model:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(\n",
        "    'saved_models/my_model_with_custom_hyper_loss.keras', custom_objects={'huber_fn': huber_fn})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2188 - mae: 0.5096 - val_loss: 0.2129 - val_mae: 0.4876\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 0.1990 - mae: 0.4809 - val_loss: 0.1891 - val_mae: 0.4610\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x15d46d84af0>"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Now, We need to control the threshold..\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_huber(threshold=1.0):\n",
        "    def huber_fn(y_true, y_pred):\n",
        "        error = y_true - y_pred\n",
        "        is_small_error = tf.abs(error) < threshold\n",
        "        squared_loss = tf.square(error) / 2\n",
        "        linear_loss = threshold * tf.abs(error) - threshold ** 2 / 2\n",
        "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
        "    return huber_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(loss=create_huber(2.0), metrics=['mae'], optimizer='nadam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2148 - mae: 0.4689 - val_loss: 0.2084 - val_mae: 0.4504\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2054 - mae: 0.4597 - val_loss: 0.1807 - val_mae: 0.4340\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x15d46d85090>"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(\"saved_models/my_model_with_a_custom_loss_threshold_2.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(\"saved_models/my_model_with_a_custom_loss_threshold_2.keras\",\n",
        "                                   custom_objects={\"huber_fn\": create_huber(2.0)})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "so the threshold will not be saved with the model, but we must pass it..\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2000 - mae: 0.4540 - val_loss: 0.1853 - val_mae: 0.4339\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - loss: 0.1959 - mae: 0.4490 - val_loss: 0.1976 - val_mae: 0.4367\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x15d498edc90>"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "now we need to build huber function that saves the threshold with it, we must use sub-classing..\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sub-Classing Custom Loss Function with automatically saved hyperparameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "@keras.utils.register_keras_serializable()\n",
        "class HuberLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, threshold=1.0, **kwargs):\n",
        "        self.threshold = threshold\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        error = y_true - y_pred\n",
        "        is_small_error = tf.abs(error) < self.threshold\n",
        "        squared_loss = tf.square(error) / 2\n",
        "        linear_loss = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
        "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"threshold\": self.threshold}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.0512 - mae: 1.1438 - val_loss: 0.5086 - val_mae: 0.6718\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 0.3170 - mae: 0.5816 - val_loss: 0.3527 - val_mae: 0.5571\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x15d49a5bdf0>"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.keras.utils.set_random_seed(42)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                          input_shape=input_shape),\n",
        "    tf.keras.layers.Dense(1),\n",
        "])\n",
        "\n",
        "model.compile(loss=HuberLoss(2.), optimizer=\"nadam\", metrics=[\"mae\"])\n",
        "\n",
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(\"saved_models/my_model_with_a_custom_loss_class.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Note: when using sub-classing, either passing the custom class used as custom objects, or decorate the class with @keras.utils.register_keras_serializable(),\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model('saved_models/my_model_with_a_custom_loss_class.keras'\n",
        "                                   #    ,custom_objects={'HuberLoss': HuberLoss}\n",
        "                                   )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<__main__.HuberLoss at 0x15d4aba27d0>"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "here's, it identify it even without passing it as custom object to load_model function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custom Activation Functions, Initializers, Regularizers,and Constraints\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "def my_softplus(z):\n",
        "    return tf.math.log(1.0 + tf.exp(z))\n",
        "\n",
        "\n",
        "def my_glorot_initializer(shape, dtype=tf.float32):\n",
        "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
        "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
        "\n",
        "\n",
        "def my_l1_regularizer(weights):\n",
        "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
        "\n",
        "\n",
        "def my_positive_weights(weights):  # return value is just tf.nn.relu(weights)\n",
        "    return tf.where(weights < 0., tf.zeros_like(weights), weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "layer = tf.keras.layers.Dense(1, activation=my_softplus,\n",
        "                              kernel_initializer=my_glorot_initializer,\n",
        "                              kernel_regularizer=my_l1_regularizer,\n",
        "                              kernel_constraint=my_positive_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Full example using custom functions above\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Invalid value for attribute `regularizer`. Expected an instance of `keras.regularizers.Regularizer`, or `None`. Received: regularizer=<function my_l1_regularizer at 0x0000015D4BC555A0>\n"
          ]
        }
      ],
      "source": [
        "tf.keras.utils.set_random_seed(42)\n",
        "\n",
        "try:\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                              input_shape=input_shape),\n",
        "        tf.keras.layers.Dense(1, activation=my_softplus,\n",
        "                              kernel_initializer=my_glorot_initializer,\n",
        "                              kernel_regularizer=my_l1_regularizer,\n",
        "                              kernel_constraint=my_positive_weights)\n",
        "    ])\n",
        "    model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])\n",
        "    model.fit(X_train_scaled, y_train, epochs=2,\n",
        "              validation_data=(X_valid_scaled, y_valid))\n",
        "    model.save(\"saved_models/my_model_with_many_custom_parts\")\n",
        "    model = tf.keras.models.load_model(\n",
        "        \"saved_models/my_model_with_many_custom_parts\",\n",
        "        custom_objects={\n",
        "            \"my_l1_regularizer\": my_l1_regularizer,\n",
        "            \"my_positive_weights\": my_positive_weights,\n",
        "            \"my_glorot_initializer\": my_glorot_initializer,\n",
        "            \"my_softplus\": my_softplus,\n",
        "        }\n",
        "    )\n",
        "    model.fit(X_train_scaled, y_train, epochs=2,\n",
        "              validation_data=(X_valid_scaled, y_valid))\n",
        "\n",
        "except Exception as ex:\n",
        "    print(ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "here's a problem with directly assignment regular functions, we should do it with sub-classing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom Regularizer\n",
        "class MyL1Regularizer(tf.keras.regularizers.Regularizer):\n",
        "    def __init__(self, factor=0.01):\n",
        "        self.factor = factor\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return tf.reduce_sum(tf.abs(self.factor * x))\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\"factor\": self.factor}\n",
        "\n",
        "# Custom Constraint\n",
        "\n",
        "\n",
        "class MyPositiveWeights(tf.keras.constraints.Constraint):\n",
        "    def __call__(self, weights):\n",
        "        return tf.nn.relu(weights)\n",
        "\n",
        "    def get_config(self):\n",
        "        return {}\n",
        "\n",
        "# Custom Initializer\n",
        "\n",
        "\n",
        "class MyGlorotInitializer(tf.keras.initializers.Initializer):\n",
        "    def __init__(self):\n",
        "        super(MyGlorotInitializer, self).__init__()\n",
        "\n",
        "    def __call__(self, shape, dtype=tf.float32):\n",
        "        stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
        "        return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
        "\n",
        "    def get_config(self):\n",
        "        return {}\n",
        "\n",
        "# Custom Activation Function\n",
        "\n",
        "\n",
        "def my_softplus(z):\n",
        "    return tf.math.log(1.0 + tf.exp(z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 2.2008 - mae: 0.9706 - val_loss: inf - val_mae: inf\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1249 - mae: 0.6767 - val_loss: inf - val_mae: inf\n",
            "Epoch 1/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.8456 - mae: 0.5999 - val_loss: 2.8737 - val_mae: 0.5737\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6909 - mae: 0.5547 - val_loss: 2.0950 - val_mae: 0.5363\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x15d4ce8d150>"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                          input_shape=input_shape),\n",
        "    tf.keras.layers.Dense(1, activation=my_softplus,\n",
        "                          kernel_initializer=MyGlorotInitializer(),\n",
        "                          kernel_regularizer=MyL1Regularizer(),\n",
        "                          kernel_constraint=MyPositiveWeights())\n",
        "])\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])\n",
        "\n",
        "# Fit model\n",
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))\n",
        "\n",
        "# Save model\n",
        "model.save(\"saved_models/my_model_with_many_custom_parts.keras\")\n",
        "\n",
        "# Load model\n",
        "model = tf.keras.models.load_model(\n",
        "    \"saved_models/my_model_with_many_custom_parts.keras\",\n",
        "    custom_objects={\n",
        "        \"MyL1Regularizer\": MyL1Regularizer,\n",
        "        \"MyPositiveWeights\": MyPositiveWeights,\n",
        "        \"MyGlorotInitializer\": MyGlorotInitializer,\n",
        "        \"my_softplus\": my_softplus,\n",
        "    }\n",
        ")\n",
        "\n",
        "# Continue training\n",
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custom Metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - huber_fn: 1.0788 - loss: 2.5942\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - huber_fn: 0.3403 - loss: 0.7644\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x15d4d035120>"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# extra code – once again, lets' create a basic Keras model\n",
        "tf.keras.utils.set_random_seed(42)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                          input_shape=input_shape),\n",
        "    tf.keras.layers.Dense(1),\n",
        "])\n",
        "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[create_huber(2.0)])\n",
        "\n",
        "model.fit(X_train_scaled, y_train, epochs=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Streaming metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.8>"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "precision = tf.keras.metrics.Precision()\n",
        "precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "precision.result()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<KerasVariable shape=(1,), dtype=float32, path=precision/true_positives>,\n",
              " <KerasVariable shape=(1,), dtype=float32, path=precision/false_positives>]"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "precision.variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "clear stored accumulated variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.0>"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "precision.reset_state()\n",
        "precision.result()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating a streaming metric:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\sayed\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "@keras.utils.register_keras_serializable()\n",
        "class HuberMetric(tf.keras.metrics.Metric):\n",
        "    def __init__(self, threshold=1.0, **kwargs):\n",
        "        super().__init__(**kwargs)  # handles base args (e.g., dtype)\n",
        "        self.threshold = threshold\n",
        "        self.huber_fn = create_huber(threshold)\n",
        "        self.total = self.add_weight(\n",
        "            name='total', initializer='zeros', shape=(), dtype=tf.float32)\n",
        "        self.count = self.add_weight(\n",
        "            name='count', initializer='zeros', shape=(), dtype=tf.float32)\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        sample_metrics = self.huber_fn(y_true, y_pred)\n",
        "        self.total.assign_add(tf.reduce_sum(sample_metrics))\n",
        "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        return self.total / self.count\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"threshold\": self.threshold}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=14.0>"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m = HuberMetric(2.)\n",
        "\n",
        "# total = 2 * |10 - 2| - 2²/2 = 14\n",
        "# count = 1\n",
        "# result = 14 / 1 = 14\n",
        "m(tf.constant([[2.]]), tf.constant([[10.]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# total = total + (|1 - 0|² / 2) + (2 * |9.25 - 5| - 2² / 2) = 14 + 7 = 21\n",
        "# count = count + 2 = 3\n",
        "# result = total / count = 21 / 3 = 7\n",
        "m(tf.constant([[0.], [5.]]), tf.constant([[1.], [9.25]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m.result()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total: 21.0\n",
            "Count: 3.0\n"
          ]
        }
      ],
      "source": [
        "print(\"Total:\", m.total.numpy())  # This should print 21.0\n",
        "print(\"Count:\", m.count.numpy())  # This should print 3.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<KerasVariable shape=(), dtype=float32, path=huber_metric/total>,\n",
              " <KerasVariable shape=(), dtype=float32, path=huber_metric/count>]"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m.variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<KerasVariable shape=(), dtype=float32, path=huber_metric/total>,\n",
              " <KerasVariable shape=(), dtype=float32, path=huber_metric/count>]"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m.reset_state()\n",
        "m.variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.keras.utils.set_random_seed(42)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                          input_shape=input_shape),\n",
        "    tf.keras.layers.Dense(1),\n",
        "])\n",
        "\n",
        "model.compile(loss=create_huber(2.0), optimizer=\"nadam\",\n",
        "              metrics=[HuberMetric(2.0)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - huber_metric_1: 1.0512 - loss: 1.0512\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - huber_metric_1: 0.3170 - loss: 0.3170\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x15d4cff8fd0>"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train_scaled, y_train, epochs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(\"saved_models/my_model_with_a_custom_metric.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(\n",
        "    \"saved_models/my_model_with_a_custom_metric.keras\",\n",
        "    custom_objects={\n",
        "        \"huber_fn\": create_huber(2.0),\n",
        "        \"HuberMetric\": HuberMetric\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - huber_metric_1: 0.2612 - loss: 0.2612\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - huber_metric_1: 0.2328 - loss: 0.2328\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x15d4bc94850>"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train_scaled, y_train, epochs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'CompileMetrics' object has no attribute 'threshold'\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    model.metrics[-1].threshold\n",
        "except Exception as ex:\n",
        "    print(ex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "for metric in model.metrics:\n",
        "    if isinstance(metric, HuberMetric):\n",
        "        print(f\"Huber Metric threshold: {metric.threshold}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "it seems like keras has updated from HOML tutorial, i will investigate where to find our threshold..\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "keras.src.trainers.compile_utils.CompileMetrics"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(model.metrics[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['__annotations__',\n",
              " '__call__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_api_export_path',\n",
              " '_api_export_symbol_id',\n",
              " '_build_metrics_set',\n",
              " '_check_super_called',\n",
              " '_dtype',\n",
              " '_flat_metrics',\n",
              " '_flat_weighted_metrics',\n",
              " '_flatten_y',\n",
              " '_metrics',\n",
              " '_obj_type',\n",
              " '_tracker',\n",
              " '_unpickle_model',\n",
              " '_user_metrics',\n",
              " '_user_weighted_metrics',\n",
              " '_variables',\n",
              " 'add_variable',\n",
              " 'add_weight',\n",
              " 'build',\n",
              " 'built',\n",
              " 'dtype',\n",
              " 'from_config',\n",
              " 'get_config',\n",
              " 'metrics',\n",
              " 'name',\n",
              " 'output_names',\n",
              " 'reset_state',\n",
              " 'result',\n",
              " 'stateless_reset_state',\n",
              " 'stateless_result',\n",
              " 'stateless_update_state',\n",
              " 'update_state',\n",
              " 'variables']"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dir(model.metrics[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "__main__.HuberMetric"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(model.metrics[-1].metrics[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2.0"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.metrics[-1].metrics[0].threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "here it is :))))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Looks like it works fine! More simply, we could have created the class like this:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HuberMetric(tf.keras.metrics.Mean):\n",
        "    def __init__(self, threshold=1.0, name='HuberMetric', dtype=None):\n",
        "        self.threshold = threshold\n",
        "        self.huber_fn = create_huber(threshold)\n",
        "        super().__init__(name=name, dtype=dtype)\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        metric = self.huber_fn(y_true, y_pred)\n",
        "        super(HuberMetric, self).update_state(metric, sample_weight)\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"threshold\": self.threshold}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597us/step - HuberMetric: 1.0599 - loss: 0.5274\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - HuberMetric: 0.3215 - loss: 0.1598\n"
          ]
        }
      ],
      "source": [
        "tf.keras.utils.set_random_seed(42)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                          input_shape=input_shape),\n",
        "    tf.keras.layers.Dense(1),\n",
        "])\n",
        "\n",
        "model.compile(loss=tf.keras.losses.Huber(2.0), optimizer=\"nadam\",\n",
        "              weighted_metrics=[HuberMetric(2.0)])\n",
        "\n",
        "np.random.seed(42)\n",
        "sample_weight = np.random.rand(len(y_train))\n",
        "history = model.fit(X_train_scaled, y_train, epochs=2,\n",
        "                    sample_weight=sample_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.3256884217262268, 0.32568849524955656)"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(history.history[\"loss\"][0],\n",
        " history.history[\"HuberMetric\"][0] * sample_weight.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(\"saved_models/my_model_with_a_custom_metric_v2.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(\"saved_models/my_model_with_a_custom_metric_v2.keras\",\n",
        "                                   custom_objects={\"HuberMetric\": HuberMetric})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597us/step - HuberMetric: 0.2627 - loss: 0.2262\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - HuberMetric: 0.2298 - loss: 0.1999\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x15d4f637520>"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train_scaled, y_train, epochs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2.0"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.metrics[-1].metrics[-1].threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custom Layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "explayer = tf.keras.layers.Lambda(lambda x: tf.exp(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.36787945, 1.        , 2.7182817 ], dtype=float32)>"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "explayer(tf.constant([-1., 0., 1.]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "or with sub-classing api\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MyDense(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, activation=None, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.activation = tf.keras.activations.get(activation)\n",
        "\n",
        "    def build(self, batch_input_shape):\n",
        "        self.kernel = self.add_weight(\n",
        "            name=\"kernel\", shape=[batch_input_shape[-1], self.units],\n",
        "            initializer=\"he_normal\")\n",
        "        self.bias = self.add_weight(\n",
        "            name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
        "\n",
        "    def call(self, X):\n",
        "        return self.activation(X @ self.kernel + self.bias)\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"units\": self.units,\n",
        "                \"activation\": tf.keras.activations.serialize(self.activation)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\sayed\\AppData\\Local\\Temp\\ipykernel_9352\\3097604586.py:3: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 926us/step - loss: 5.7265 - val_loss: 6.9255\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 0.9550 - val_loss: 2.6011\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 0.7227\n"
          ]
        }
      ],
      "source": [
        "tf.keras.utils.set_random_seed(42)\n",
        "model = tf.keras.Sequential([\n",
        "    MyDense(30, activation=\"relu\", input_shape=input_shape),\n",
        "    MyDense(1)\n",
        "])\n",
        "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))\n",
        "model.evaluate(X_test_scaled, y_test)\n",
        "model.save(\"saved_models/my_model_with_a_custom_layer.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 913us/step - loss: 0.7034 - val_loss: 0.8613\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - loss: 0.5803 - val_loss: 0.4588\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x15d518c23b0>"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = tf.keras.models.load_model(\"saved_models/my_model_with_a_custom_layer.keras\",\n",
        "                                   custom_objects={\"MyDense\": MyDense})\n",
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MyMultiLayer(tf.keras.layers.Layer):\n",
        "    def call(self, X):\n",
        "        X1, X2 = X\n",
        "        return X1+X2, X1*X2, X1/X2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<KerasTensor shape=(None, 2), dtype=float32, sparse=False, name=keras_tensor_20>,\n",
              " <KerasTensor shape=(None, 2), dtype=float32, sparse=False, name=keras_tensor_21>,\n",
              " <KerasTensor shape=(None, 2), dtype=float32, sparse=False, name=keras_tensor_22>)"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs1 = tf.keras.layers.Input(shape=[2])\n",
        "inputs2 = tf.keras.layers.Input(shape=[2])\n",
        "MyMultiLayer()((inputs1, inputs2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              " array([[ 9., 18.],\n",
              "        [ 6., 10.]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              " array([[18., 72.],\n",
              "        [ 8., 21.]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              " array([[0.5      , 0.5      ],\n",
              "        [0.5      , 2.3333333]], dtype=float32)>)"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X1, X2 = np.array([[3., 6.], [2., 7.]]), np.array([[6., 12.], [4., 3.]])\n",
        "MyMultiLayer()((X1, X2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's create a layer with a different behavior during training and testing:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MyGaussianNoise(tf.keras.layers.Layer):\n",
        "    def __init__(self, stddev, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.stddev = stddev\n",
        "\n",
        "    def call(self, X, training=None):\n",
        "        if training:\n",
        "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
        "            return X + noise\n",
        "        return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\sayed\\AppData\\Local\\Temp\\ipykernel_9352\\1546716026.py:3: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 959us/step - loss: 2.7619 - val_loss: 25.1369\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 1.3951 - val_loss: 14.9793\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - loss: 1.1219\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1.1244221925735474"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.keras.utils.set_random_seed(42)\n",
        "model = tf.keras.Sequential([\n",
        "    MyGaussianNoise(stddev=1.0, input_shape=input_shape),\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\",\n",
        "                          kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))\n",
        "model.evaluate(X_test_scaled, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custom Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tf.keras.utils.register_keras_serializable()\n",
        "class ResidualBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, n_layers, n_units, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.n_layers = n_layers\n",
        "        self.n_units = n_units\n",
        "        self.hidden = [tf.keras.layers.Dense(\n",
        "            n_units, activation='relu', kernel_initializer=\"he_normal\")\n",
        "            for _ in range(n_layers)]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        Z = inputs\n",
        "        for layer in self.hidden:\n",
        "            Z = layer(Z)\n",
        "        return Z + inputs\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"n_layers\": self.n_layers,\n",
        "            \"n_units\": self.n_units,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class ResidualRegressor(tf.keras.models.Model):\n",
        "    def __init__(self, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.output_dim = output_dim\n",
        "        self.linear1 = tf.keras.layers.Dense(30)\n",
        "        self.rBlock1 = ResidualBlock(2, 30)\n",
        "        self.rBlock2 = ResidualBlock(2, 30)\n",
        "        self.out = tf.keras.layers.Dense(output_dim)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        Z = self.linear1(inputs)\n",
        "        for _ in range(1+3):\n",
        "            Z = self.rBlock1(Z)\n",
        "        Z = self.rBlock2(Z)\n",
        "        return self.out(Z)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 869us/step - loss: 38.7647\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - loss: 0.9498\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 0.5812\n",
            "Epoch 1/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 791us/step - loss: 0.6747\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 0.5269\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[1.0190629],\n",
              "       [1.8359567],\n",
              "       [4.045906 ]], dtype=float32)"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.keras.utils.set_random_seed(42)\n",
        "model = ResidualRegressor(1)\n",
        "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
        "history = model.fit(X_train_scaled, y_train, epochs=2)\n",
        "score = model.evaluate(X_test_scaled, y_test)\n",
        "model.save(\"saved_models/my_custom_model.keras\")\n",
        "\n",
        "model = tf.keras.models.load_model(\"saved_models/my_custom_model.keras\")\n",
        "history = model.fit(X_train_scaled, y_train, epochs=2)\n",
        "model.predict(X_test_scaled[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Losses and Metrics Based on Model Internals\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ReconstructingRegressor(tf.keras.Model):\n",
        "    def __init__(self, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.hidden = [tf.keras.layers.Dense(30, activation=\"relu\",\n",
        "                                             kernel_initializer=\"he_normal\")\n",
        "                       for _ in range(5)]\n",
        "        self.out = tf.keras.layers.Dense(output_dim)\n",
        "        self.reconstruction_mean = tf.keras.metrics.Mean(\n",
        "            name=\"reconstruction_error\")\n",
        "\n",
        "    def build(self, batch_input_shape):\n",
        "        n_inputs = batch_input_shape[-1]\n",
        "        self.reconstruct = tf.keras.layers.Dense(n_inputs)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        Z = inputs\n",
        "        for layer in self.hidden:\n",
        "            Z = layer(Z)\n",
        "        reconstruction = self.reconstruct(Z)\n",
        "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
        "        self.add_loss(0.05 * recon_loss)\n",
        "        if training:\n",
        "            result = self.reconstruction_mean(recon_loss)\n",
        "            self.add_metric(result)\n",
        "        return self.out(Z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "error due to changes in tf new version (add metric deleted)\n"
          ]
        }
      ],
      "source": [
        "tf.keras.utils.set_random_seed(42)\n",
        "try:\n",
        "    model = ReconstructingRegressor(1)\n",
        "    model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
        "    history = model.fit(X_train_scaled, y_train, epochs=5)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "except:\n",
        "    print('error due to changes in tf new version (add metric deleted)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Computing Gradients Using Autodiff\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "105"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def f(w1, w2):\n",
        "    return 3*w1**2 + 2*w1*w2\n",
        "\n",
        "\n",
        "f(5, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "36.000001500724466"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w1, w2 = 5, 3\n",
        "eps = 5e-7\n",
        "(f(w1+eps, w2) - f(w1, w2))/eps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10.000000003174137"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(f(w1, w2 + eps) - f(w1, w2)) / eps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [],
      "source": [
        "w1, w2 = tf.Variable(5.0), tf.Variable(3.0)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    z = f(w1, w2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=36.0>"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tape.gradient(z, w1)  # dz/dw1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    print(tape.gradient(z, w2))\n",
        "except Exception as ex:\n",
        "    print(ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "that happen because the tape is deleted once it used, preventing accumulating the gradients.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(36.0, shape=(), dtype=float32)\n",
            "tf.Tensor(10.0, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "with tf.GradientTape(persistent=True) as tape:\n",
        "    z = f(w1, w2)\n",
        "print(tape.gradient(z, w1))\n",
        "print(tape.gradient(z, w2))\n",
        "del tape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "can compute gradient for all variables once:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w1, w2 = tf.Variable(5.), tf.Variable(3.)\n",
        "with tf.GradientTape() as tape:\n",
        "    z = f(w1, w2)\n",
        "\n",
        "gradients = tape.gradient(z, [w1, w2])\n",
        "gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "can't compute gradients for constant directly:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[None, None]"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "c1, c2 = tf.constant(5.0), tf.constant(3.0)\n",
        "with tf.GradientTape() as tape:\n",
        "    z = f(c1, c2)\n",
        "\n",
        "tape.gradient(z, [c1, c2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "fixed by forcing tf to watch them:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "c1, c2 = tf.constant(5.0), tf.constant(3.0)\n",
        "with tf.GradientTape() as tape:\n",
        "    tape.watch([c1, c2])\n",
        "    z = f(c1, c2)\n",
        "\n",
        "tape.gradient(z, [c1, c2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=136.0>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=30.0>]"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# extra code – if given a vector, tape.gradient() will compute the gradient of\n",
        "#              the vector's sum.\n",
        "with tf.GradientTape() as tape:\n",
        "    z1 = f(w1, w2 + 2.)\n",
        "    z2 = f(w1, w2 + 5.)\n",
        "    z3 = f(w1, w2 + 7.)\n",
        "\n",
        "tape.gradient([z1, z2, z3], [w1, w2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=136.0>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=30.0>]"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# extra code – shows that we get the same result as the previous cell\n",
        "with tf.GradientTape() as tape:\n",
        "    z1 = f(w1, w2 + 2.)\n",
        "    z2 = f(w1, w2 + 5.)\n",
        "    z3 = f(w1, w2 + 7.)\n",
        "    z = z1 + z2 + z3\n",
        "\n",
        "tape.gradient(z, [w1, w2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [],
      "source": [
        "# extra code – shows how to compute the jacobians and the hessians\n",
        "\n",
        "with tf.GradientTape(persistent=True) as hessian_tape:\n",
        "    with tf.GradientTape() as jacobian_tape:\n",
        "        z = f(w1, w2)\n",
        "    jacobians = jacobian_tape.gradient(z, [w1, w2])\n",
        "hessians = [hessian_tape.gradient(jacobian, [w1, w2])\n",
        "            for jacobian in jacobians]\n",
        "del hessian_tape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[<tf.Tensor: shape=(), dtype=float32, numpy=6.0>,\n",
              "  <tf.Tensor: shape=(), dtype=float32, numpy=2.0>],\n",
              " [<tf.Tensor: shape=(), dtype=float32, numpy=2.0>, None]]"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hessians"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Blocking gradients\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=30.0>, None]"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def f(w1, w2):\n",
        "    # this will act normally on forward pass, but block/neglect the second part in backpropagation\n",
        "    return 3*w1**2 + tf.stop_gradient(2*w1*w2)\n",
        "\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    z = f(w1, w2)\n",
        "tape.gradient(z, [w1, w2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "numerical issues when using sqrt at very small values:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=inf>]"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = tf.Variable(1e-50)\n",
        "with tf.GradientTape() as tape:\n",
        "    z = tf.sqrt(x)\n",
        "\n",
        "tape.gradient(z, [x])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "it produces inf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=inf>]"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = tf.Variable(1e-50)\n",
        "with tf.GradientTape() as tape:\n",
        "    z = tf.sqrt(x)\n",
        "\n",
        "tape.gradient(z, [x])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "converting to float64 increase the precision and solves the problem\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float64, numpy=4.999999999999999e+24>]"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = tf.Variable(1e-50, dtype=tf.float64)\n",
        "with tf.GradientTape() as tape:\n",
        "    z = tf.sqrt(x)\n",
        "\n",
        "tape.gradient(z, [x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=30.0>"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.math.log(tf.exp(tf.constant(30., dtype=tf.float32))+1.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [],
      "source": [
        "def my_softplus(z):\n",
        "    return tf.math.log(1.0 + tf.exp(z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=inf>"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_softplus(100.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "it explodes due to exp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {},
      "outputs": [],
      "source": [
        "# rewrite it to be more stable\n",
        "def my_softplus(z):\n",
        "    return tf.math.log(1 + tf.exp(-tf.abs(z))) + tf.maximum(0., z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=100.0>"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_softplus(100.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "works fine..\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "rewrite the function with stable gradients:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tf.custom_gradient\n",
        "def my_softplus(z):\n",
        "    def my_softplus_gradients(grads):\n",
        "        return grads * (1 - 1/(1+tf.exp(z)))\n",
        "    result = tf.math.log(1 + tf.exp(-tf.abs(z))) + tf.maximum(0., z)\n",
        "    return result, my_softplus_gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1000.], dtype=float32)>,\n",
              " [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>])"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# extra code – shows that the function is now stable, as well as its gradients\n",
        "x = tf.Variable([1000.])\n",
        "with tf.GradientTape() as tape:\n",
        "    z = my_softplus(x)\n",
        "\n",
        "z, tape.gradient(z, [x])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custom Training Loops:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.keras.utils.set_random_seed(42)  # extra code – to ensure reproducibility\n",
        "l2_reg = tf.keras.regularizers.l2(0.05)\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                          kernel_regularizer=l2_reg),\n",
        "    tf.keras.layers.Dense(1, kernel_regularizer=l2_reg)\n",
        "])\n",
        "\n",
        "\n",
        "def random_batch(X, y, batch_size=32):\n",
        "    idx = np.random.randint(len(X), size=batch_size)\n",
        "    return X[idx], y[idx]\n",
        "\n",
        "\n",
        "def print_status_bar(step, total, loss, metrics=None):\n",
        "    metrics = \" - \".join([f\"{m.name}: {m.result():.4f}\"\n",
        "                          for m in [loss] + (metrics or [])])\n",
        "    end = \"\" if step < total else \"\\n\"\n",
        "    print(f\"\\r{step}/{total} - \" + metrics, end=end)\n",
        "\n",
        "# \\r moves the cursor to the start of the current line to make the visual changes like fit() method progress\n",
        "\n",
        "\n",
        "tf.keras.utils.set_random_seed(42)\n",
        "\n",
        "n_epochs = 5\n",
        "batch_size = 32\n",
        "n_steps = len(X_train) // batch_size\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "loss_fn = tf.keras.losses.mse\n",
        "mean_loss = tf.keras.metrics.Mean()\n",
        "metrics = [tf.keras.metrics.MeanAbsoluteError()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "362/362 - mean: 3.5380 - mean_absolute_error: 0.6633\n",
            "Epoch 2/5\n",
            "362/362 - mean: 1.8658 - mean_absolute_error: 0.5431\n",
            "Epoch 3/5\n",
            "362/362 - mean: 1.1396 - mean_absolute_error: 0.5027\n",
            "Epoch 4/5\n",
            "362/362 - mean: 0.8489 - mean_absolute_error: 0.4980\n",
            "Epoch 5/5\n",
            "362/362 - mean: 0.7253 - mean_absolute_error: 0.5007\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, n_epochs+1):\n",
        "    print(f\"Epoch {epoch}/{n_epochs}\")\n",
        "    for step in range(1+n_steps):\n",
        "        X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = model(X_batch, training=True)\n",
        "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
        "            loss = tf.add_n([main_loss] + model.losses)\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "        # extra code – if your model has variable constraints\n",
        "        for variable in model.variables:\n",
        "            if variable.constraint is not None:\n",
        "                variable.assign(variable.constraint(variable))\n",
        "\n",
        "        mean_loss(loss)\n",
        "        for metric in metrics:\n",
        "            metric(y_batch, y_pred)\n",
        "\n",
        "        print_status_bar(step, n_steps, mean_loss, metrics)\n",
        "\n",
        "    for metric in [mean_loss] + metrics:\n",
        "        try:\n",
        "            metric.reset_states()\n",
        "        except:\n",
        "            metric.reset_state()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "extra code – shows how to use the tqdm package to display nice progress bars\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8bc778a72b684742a25085ce21b7bbf7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "All epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2949196f5fcf4f88936212566317b056",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 1/5:   0%|          | 0/362 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8941f0e4d9124b54ac995b13f7a614fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 2/5:   0%|          | 0/362 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05203493d2c6451f80b7d4630a7ad5b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 3/5:   0%|          | 0/362 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b51ee61868314680b0d3bfcc80792709",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 4/5:   0%|          | 0/362 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0e7d4a56e77400a95c2acdfc17713ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 5/5:   0%|          | 0/362 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from tqdm.notebook import trange\n",
        "from collections import OrderedDict\n",
        "with trange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
        "    for epoch in epochs:\n",
        "        with trange(1, n_steps + 1, desc=f\"Epoch {epoch}/{n_epochs}\") as steps:\n",
        "            for step in steps:\n",
        "                X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
        "                with tf.GradientTape() as tape:\n",
        "                    y_pred = model(X_batch)\n",
        "                    main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
        "                    loss = tf.add_n([main_loss] + model.losses)\n",
        "\n",
        "                gradients = tape.gradient(loss, model.trainable_variables)\n",
        "                optimizer.apply_gradients(\n",
        "                    zip(gradients, model.trainable_variables))\n",
        "\n",
        "                for variable in model.variables:\n",
        "                    if variable.constraint is not None:\n",
        "                        variable.assign(variable.constraint(variable))\n",
        "\n",
        "                status = OrderedDict()\n",
        "                mean_loss(loss)\n",
        "                status[\"loss\"] = mean_loss.result().numpy()\n",
        "                for metric in metrics:\n",
        "                    metric(y_batch, y_pred)\n",
        "                    status[metric.name] = metric.result().numpy()\n",
        "\n",
        "                steps.set_postfix(status)\n",
        "\n",
        "        for metric in [mean_loss] + metrics:\n",
        "            try:\n",
        "                metric.reset_states()\n",
        "            except:\n",
        "                metric.reset_state()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TensorFlow Functions and Graphs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "execution_count": 145,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def cube(n):\n",
        "    return n**3\n",
        "\n",
        "\n",
        "cube(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cube(tf.Variable(2.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
            ]
          },
          "execution_count": 147,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cube(tf.constant(2.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x15d5609ef50>"
            ]
          },
          "execution_count": 148,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.function(cube)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x15d5609fa00>"
            ]
          },
          "execution_count": 149,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf_cube = tf.function(cube)\n",
        "tf_cube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
            ]
          },
          "execution_count": 150,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf_cube(2.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function cube at 0x0000015D54F61120> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
            ]
          },
          "execution_count": 151,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf_cube(tf.constant(2.0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "we can also use decorator:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function cube at 0x0000015D52D70AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
            ]
          },
          "execution_count": 152,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "@tf.function\n",
        "def cube(n):\n",
        "    return n**3\n",
        "\n",
        "\n",
        "cube(2.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "the original python function still available:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function __main__.cube(n)>"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf_cube.python_function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8.0"
            ]
          },
          "execution_count": 154,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf_cube.python_function(2.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "let's try XLA (accelerated linear algebra) optimization in code by putting jit_compile=True in compile function:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n",
            "Available devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Check if GPU is available\n",
        "print(\"Num GPUs Available: \", len(\n",
        "    tf.config.experimental.list_physical_devices('GPU')))\n",
        "\n",
        "# List available devices\n",
        "print(\"Available devices:\", tf.config.experimental.list_physical_devices())\n",
        "\n",
        "\n",
        "# nvidia-smi for real time gpu monitoring"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
