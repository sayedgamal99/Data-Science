{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fGtAg7QSBq_r"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-8IvGXjEHTS"
      },
      "source": [
        "### Tensors and Operations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abXFEq0TCVgd",
        "outputId": "67d306d9-493d-4fe8-a8d5-6bde9715d7ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "array([[1, 2, 3],\n",
              "       [4, 5, 6]])>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
        "t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtrxHqs6CDyE",
        "outputId": "5218c4c7-33d7-44c3-ab26-72f97f49f794"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([2, 3])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfPoBDoQCL6r",
        "outputId": "011f0136-4b2f-49c2-b9fb-40834784f7a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 2, 3],\n",
              "       [4, 5, 6]])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOGZ3XpACa08",
        "outputId": "4076f570-f2af-433c-a2f8-5bb6bc421662"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor([3 6], shape=(2,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "print(t[0, 0])\n",
        "print(t[:, 2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW7yulK2CkWt",
        "outputId": "2bcd6aa9-9f88-4178-f1ee-aa8680dc948d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "array([[1, 2, 3],\n",
              "       [4, 5, 6]])>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t[..., :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75SMYYhxCr2n",
        "outputId": "7a069021-13e1-4de7-97d1-41fe24adf786"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 1), dtype=int32, numpy=\n",
              "array([[2],\n",
              "       [5]])>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t[..., 1, tf.newaxis]  # keep dimension 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBMU0W7vCvrH",
        "outputId": "b662b89b-4b70-461c-bf24-a3809acfb8ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "array([[11, 12, 13],\n",
              "       [14, 15, 16]])>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t+10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhIJaQ5NDC7B",
        "outputId": "1acf142a-ae62-4f6a-fd3a-2c2070f85481"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "array([[11, 12, 13],\n",
              "       [14, 15, 16]])>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.__add__(10)  # not in-place"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2qCPPCnDIr5",
        "outputId": "f47b9c7f-b456-41f7-9790-a8e37a683ff0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "array([[1, 2, 3],\n",
              "       [4, 5, 6]])>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3H74DoKDJOp",
        "outputId": "bb5cd6f5-3c0d-40ef-d09a-63cd3998ab7e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "array([[ 1,  4,  9],\n",
              "       [16, 25, 36]])>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.square(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czcO0XNGDT0q",
        "outputId": "84d0b8d6-1e09-47e3-afa2-31171c00b516"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[14, 32],\n",
              "       [32, 77]])>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t @ tf.transpose(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdSHOi0IEJZy"
      },
      "source": [
        "### Tensors and NumPy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "XK4z68RIDYHL"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cpl4hUOnDo4m",
        "outputId": "4157ccee-8349-448e-f6b9-bc574b753e7b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = np.array([2., 4., 5.])\n",
        "tf.constant(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiR6xyc-DsIu",
        "outputId": "1b52a024-a775-473a-e752-3b679aa578dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 4., 16., 25.])>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.square(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q25m4wqUD2l-",
        "outputId": "cf272777-c97f-4af7-97f8-8e2412d9bfbf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 1,  4,  9],\n",
              "       [16, 25, 36]])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.square(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dsh752mDEBgI"
      },
      "source": [
        "### Type Conversions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bcgeno05D9Av",
        "outputId": "e0ae7029-8c30-431e-8ee8-cc2632e9d998"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2] name: \n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    tf.constant(2.0) + tf.constant(40)\n",
        "except tf.errors.InvalidArgumentError as ex:\n",
        "    print(ex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTukCIaRERAE",
        "outputId": "4cdb38e2-5a4a-45f6-874f-461e60aa429f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:AddV2] name: \n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    tf.constant(2.0) + tf.constant(40., dtype=tf.float64)\n",
        "except tf.errors.InvalidArgumentError as ex:\n",
        "    # defualt values in tensorflow are float32, cannot manipulated with float64\n",
        "    print(ex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isV2hM-eEXEr",
        "outputId": "848170b9-29b1-42a3-ef5a-6d58e2f6dca4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=52.0>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.constant(2.) + tf.constant(50, dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AWQrWY7EZZD",
        "outputId": "36a67bd8-0aee-47f4-a9e7-962a50557903"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t2 = tf.constant(40, dtype=tf.float64)\n",
        "tf.constant(2.) + tf.cast(t2, tf.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-ClwN2VEypv"
      },
      "source": [
        "### Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfqKM28PEqjd",
        "outputId": "7312ae39-2d8d-41f6-85e4-cab9ffc1b5b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
              "array([[1., 2., 3.],\n",
              "       [4., 5., 6.]], dtype=float32)>"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])\n",
        "v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGxDnKMIE4bX",
        "outputId": "d8d8804f-0369-4a52-948a-217acac64138"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
              "array([[ 2.,  4.,  6.],\n",
              "       [ 8., 10., 12.]], dtype=float32)>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v.assign(2*v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riLfpqFJFAoH",
        "outputId": "6847fd80-f7e6-4ac9-b050-9a8afa858f06"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
              "array([[ 2.,  4.,  6.],\n",
              "       [ 8., 10., 12.]], dtype=float32)>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op2QQS7mFBzo",
        "outputId": "3faf6d78-bbde-4ce8-90af-a44f76d63077"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
              "array([[42.,  4.,  6.],\n",
              "       [ 8., 10., 12.]], dtype=float32)>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v[0, 0].assign(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RASTIl7sFF_g",
        "outputId": "0d41726a-d1e3-456f-ba89-f4de384489cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
              "array([[100.,   4.,   6.],\n",
              "       [400.,  10.,  12.]], dtype=float32)>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v.scatter_nd_update(indices=[[0, 0], [1, 0]], updates=[100, 400])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vtVimYKHDd3",
        "outputId": "4ca2ee01-d1cd-4da2-e59a-61dde0eb68e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    t[1] = [7., 8., 9.]  # cannot update with direct assignment\n",
        "except TypeError as ex:\n",
        "    print(ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custom Loss Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "def huber_fn(y_true, y_pred):\n",
        "    \"\"\"combine MSE smoothing property (at small values) and MAE outliers robustness property (at large values)\"\"\"\n",
        "    error = abs(y_true-y_pred)\n",
        "    squared = tf.square(error) / 2  # smoothing gradients factor\n",
        "    # -.5 for connection guaranteed between two losses at the threshold (1 here)\n",
        "    linear = error - .5\n",
        "    return tf.where(error < 1, squared, linear)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\sayed\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_valid_scaled = scaler.transform(X_valid)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "input_shape = X_train.shape[1:]\n",
        "\n",
        "tf.keras.utils.set_random_seed(42)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                          input_shape=input_shape),\n",
        "    tf.keras.layers.Dense(1),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7494 - mae: 1.1371 - val_loss: 0.3474 - val_mae: 0.6522\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - loss: 0.2607 - mae: 0.5681 - val_loss: 0.2553 - val_mae: 0.5383\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x18be506d1b0>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(loss=huber_fn, metrics=['mae'], optimizer='nadam')\n",
        "\n",
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Saving/Loading Models with Custom objects\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs('saved_models', exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('saved_models/my_model_with_custom_hyper_loss.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the model:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(\n",
        "    'saved_models/my_model_with_custom_hyper_loss.keras', custom_objects={'huber_fn': huber_fn})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2188 - mae: 0.5096 - val_loss: 0.2129 - val_mae: 0.4876\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 0.1990 - mae: 0.4809 - val_loss: 0.1891 - val_mae: 0.4610\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x18be8bce0e0>"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Now, We need to control the threshold..\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_huber(threshold=1.0):\n",
        "    def huber_fn(y_true, y_pred):\n",
        "        error = y_true - y_pred\n",
        "        is_small_error = tf.abs(error) < threshold\n",
        "        squared_loss = tf.square(error) / 2\n",
        "        linear_loss = threshold * tf.abs(error) - threshold ** 2 / 2\n",
        "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
        "    return huber_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(loss=create_huber(2.0), metrics=['mae'], optimizer='nadam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2148 - mae: 0.4689 - val_loss: 0.2084 - val_mae: 0.4504\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - loss: 0.2054 - mae: 0.4597 - val_loss: 0.1807 - val_mae: 0.4340\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x18be951b9a0>"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(\"saved_models/my_model_with_a_custom_loss_threshold_2.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(\"saved_models/my_model_with_a_custom_loss_threshold_2.keras\",\n",
        "                                   custom_objects={\"huber_fn\": create_huber(2.0)})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "so the threshold will not be saved with the model, but we must pass it..\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2000 - mae: 0.4540 - val_loss: 0.1853 - val_mae: 0.4339\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - loss: 0.1959 - mae: 0.4490 - val_loss: 0.1976 - val_mae: 0.4367\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x18bea6c20b0>"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "now we need to build huber function that saves the threshold with it, we must use sub-classing..\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sub-Classing Custom Loss Function with automatically saved hyperparameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "@keras.utils.register_keras_serializable()\n",
        "class HuberLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, threshold=1.0, **kwargs):\n",
        "        self.threshold = threshold\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        error = y_true - y_pred\n",
        "        is_small_error = tf.abs(error) < self.threshold\n",
        "        squared_loss = tf.square(error) / 2\n",
        "        linear_loss = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
        "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"threshold\": self.threshold}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.0512 - mae: 1.1438 - val_loss: 0.5086 - val_mae: 0.6718\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - loss: 0.3170 - mae: 0.5816 - val_loss: 0.3527 - val_mae: 0.5571\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x18bea87d4b0>"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.keras.utils.set_random_seed(42)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                          input_shape=input_shape),\n",
        "    tf.keras.layers.Dense(1),\n",
        "])\n",
        "\n",
        "model.compile(loss=HuberLoss(2.), optimizer=\"nadam\", metrics=[\"mae\"])\n",
        "\n",
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(\"saved_models/my_model_with_a_custom_loss_class.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Note: when using sub-classing, either passing the custom class used as custom objects, or decorate the class with @keras.utils.register_keras_serializable(),\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model('saved_models/my_model_with_a_custom_loss_class.keras'\n",
        "                                   #    ,custom_objects={'HuberLoss': HuberLoss}\n",
        "                                   )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<__main__.HuberLoss at 0x18beba262f0>"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "here's, it identify it even without passing it as custom object to load_model function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custom Activation Functions, Initializers, Regularizers,and Constraints\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "def my_softplus(z):\n",
        "    return tf.math.log(1.0 + tf.exp(z))\n",
        "\n",
        "\n",
        "def my_glorot_initializer(shape, dtype=tf.float32):\n",
        "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
        "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
        "\n",
        "\n",
        "def my_l1_regularizer(weights):\n",
        "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
        "\n",
        "\n",
        "def my_positive_weights(weights):  # return value is just tf.nn.relu(weights)\n",
        "    return tf.where(weights < 0., tf.zeros_like(weights), weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "layer = tf.keras.layers.Dense(1, activation=my_softplus,\n",
        "                              kernel_initializer=my_glorot_initializer,\n",
        "                              kernel_regularizer=my_l1_regularizer,\n",
        "                              kernel_constraint=my_positive_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Full example using custom functions above\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Invalid value for attribute `regularizer`. Expected an instance of `keras.regularizers.Regularizer`, or `None`. Received: regularizer=<function my_l1_regularizer at 0x0000018BEB877520>\n"
          ]
        }
      ],
      "source": [
        "tf.keras.utils.set_random_seed(42)\n",
        "\n",
        "try:\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                              input_shape=input_shape),\n",
        "        tf.keras.layers.Dense(1, activation=my_softplus,\n",
        "                              kernel_initializer=my_glorot_initializer,\n",
        "                              kernel_regularizer=my_l1_regularizer,\n",
        "                              kernel_constraint=my_positive_weights)\n",
        "    ])\n",
        "    model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])\n",
        "    model.fit(X_train_scaled, y_train, epochs=2,\n",
        "              validation_data=(X_valid_scaled, y_valid))\n",
        "    model.save(\"saved_models/my_model_with_many_custom_parts\")\n",
        "    model = tf.keras.models.load_model(\n",
        "        \"saved_models/my_model_with_many_custom_parts\",\n",
        "        custom_objects={\n",
        "            \"my_l1_regularizer\": my_l1_regularizer,\n",
        "            \"my_positive_weights\": my_positive_weights,\n",
        "            \"my_glorot_initializer\": my_glorot_initializer,\n",
        "            \"my_softplus\": my_softplus,\n",
        "        }\n",
        "    )\n",
        "    model.fit(X_train_scaled, y_train, epochs=2,\n",
        "              validation_data=(X_valid_scaled, y_valid))\n",
        "\n",
        "except Exception as ex:\n",
        "    print(ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "here's a problem with directly assignment regular functions, we should do it with sub-classing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom Regularizer\n",
        "class MyL1Regularizer(tf.keras.regularizers.Regularizer):\n",
        "    def __init__(self, factor=0.01):\n",
        "        self.factor = factor\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return tf.reduce_sum(tf.abs(self.factor * x))\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\"factor\": self.factor}\n",
        "\n",
        "# Custom Constraint\n",
        "\n",
        "\n",
        "class MyPositiveWeights(tf.keras.constraints.Constraint):\n",
        "    def __call__(self, weights):\n",
        "        return tf.nn.relu(weights)\n",
        "\n",
        "    def get_config(self):\n",
        "        return {}\n",
        "\n",
        "# Custom Initializer\n",
        "\n",
        "\n",
        "class MyGlorotInitializer(tf.keras.initializers.Initializer):\n",
        "    def __init__(self):\n",
        "        super(MyGlorotInitializer, self).__init__()\n",
        "\n",
        "    def __call__(self, shape, dtype=tf.float32):\n",
        "        stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
        "        return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
        "\n",
        "    def get_config(self):\n",
        "        return {}\n",
        "\n",
        "# Custom Activation Function\n",
        "\n",
        "\n",
        "def my_softplus(z):\n",
        "    return tf.math.log(1.0 + tf.exp(z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 2.2008 - mae: 0.9706 - val_loss: inf - val_mae: inf\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - loss: 1.1249 - mae: 0.6767 - val_loss: inf - val_mae: inf\n",
            "Epoch 1/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.8456 - mae: 0.5999 - val_loss: 2.8737 - val_mae: 0.5737\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 0.6909 - mae: 0.5547 - val_loss: 2.0950 - val_mae: 0.5363\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x18becc960e0>"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                          input_shape=input_shape),\n",
        "    tf.keras.layers.Dense(1, activation=my_softplus,\n",
        "                          kernel_initializer=MyGlorotInitializer(),\n",
        "                          kernel_regularizer=MyL1Regularizer(),\n",
        "                          kernel_constraint=MyPositiveWeights())\n",
        "])\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])\n",
        "\n",
        "# Fit model\n",
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))\n",
        "\n",
        "# Save model\n",
        "model.save(\"saved_models/my_model_with_many_custom_parts.keras\")\n",
        "\n",
        "# Load model\n",
        "model = tf.keras.models.load_model(\n",
        "    \"saved_models/my_model_with_many_custom_parts.keras\",\n",
        "    custom_objects={\n",
        "        \"MyL1Regularizer\": MyL1Regularizer,\n",
        "        \"MyPositiveWeights\": MyPositiveWeights,\n",
        "        \"MyGlorotInitializer\": MyGlorotInitializer,\n",
        "        \"my_softplus\": my_softplus,\n",
        "    }\n",
        ")\n",
        "\n",
        "# Continue training\n",
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custom Metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 680us/step - huber_fn: 1.0788 - loss: 2.5942\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - huber_fn: 0.3403 - loss: 0.7644\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x18bedde60b0>"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# extra code – once again, lets' create a basic Keras model\n",
        "tf.keras.utils.set_random_seed(42)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                          input_shape=input_shape),\n",
        "    tf.keras.layers.Dense(1),\n",
        "])\n",
        "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[create_huber(2.0)])\n",
        "\n",
        "model.fit(X_train_scaled, y_train, epochs=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Streaming metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.8>"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "precision = tf.keras.metrics.Precision()\n",
        "precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "precision.result()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<KerasVariable shape=(1,), dtype=float32, path=precision/true_positives>,\n",
              " <KerasVariable shape=(1,), dtype=float32, path=precision/false_positives>]"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "precision.variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "clear stored accumulated variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.0>"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "precision.reset_state()\n",
        "precision.result()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating a streaming metric:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\sayed\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "@keras.utils.register_keras_serializable()\n",
        "class HuberMetric(tf.keras.metrics.Metric):\n",
        "    def __init__(self, threshold=1.0, **kwargs):\n",
        "        super().__init__(**kwargs)  # handles base args (e.g., dtype)\n",
        "        self.threshold = threshold\n",
        "        self.huber_fn = create_huber(threshold)\n",
        "        self.total = self.add_weight(\n",
        "            name='total', initializer='zeros', shape=(), dtype=tf.float32)\n",
        "        self.count = self.add_weight(\n",
        "            name='count', initializer='zeros', shape=(), dtype=tf.float32)\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        sample_metrics = self.huber_fn(y_true, y_pred)\n",
        "        self.total.assign_add(tf.reduce_sum(sample_metrics))\n",
        "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        return self.total / self.count\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"threshold\": self.threshold}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=14.0>"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m = HuberMetric(2.)\n",
        "\n",
        "# total = 2 * |10 - 2| - 2²/2 = 14\n",
        "# count = 1\n",
        "# result = 14 / 1 = 14\n",
        "m(tf.constant([[2.]]), tf.constant([[10.]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# total = total + (|1 - 0|² / 2) + (2 * |9.25 - 5| - 2² / 2) = 14 + 7 = 21\n",
        "# count = count + 2 = 3\n",
        "# result = total / count = 21 / 3 = 7\n",
        "m(tf.constant([[0.], [5.]]), tf.constant([[1.], [9.25]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m.result()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total: 21.0\n",
            "Count: 3.0\n"
          ]
        }
      ],
      "source": [
        "print(\"Total:\", m.total.numpy())  # This should print 21.0\n",
        "print(\"Count:\", m.count.numpy())  # This should print 3.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<KerasVariable shape=(), dtype=float32, path=huber_metric/total>,\n",
              " <KerasVariable shape=(), dtype=float32, path=huber_metric/count>]"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m.variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<KerasVariable shape=(), dtype=float32, path=huber_metric/total>,\n",
              " <KerasVariable shape=(), dtype=float32, path=huber_metric/count>]"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m.reset_state()\n",
        "m.variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.keras.utils.set_random_seed(42)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                          input_shape=input_shape),\n",
        "    tf.keras.layers.Dense(1),\n",
        "])\n",
        "\n",
        "model.compile(loss=create_huber(2.0), optimizer=\"nadam\",\n",
        "              metrics=[HuberMetric(2.0)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 607us/step - huber_metric_1: 1.0512 - loss: 1.0512\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - huber_metric_1: 0.3170 - loss: 0.3170\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x18beef343a0>"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train_scaled, y_train, epochs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(\"saved_models/my_model_with_a_custom_metric.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(\n",
        "    \"saved_models/my_model_with_a_custom_metric.keras\",\n",
        "    custom_objects={\n",
        "        \"huber_fn\": create_huber(2.0),\n",
        "        \"HuberMetric\": HuberMetric\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - huber_metric_1: 0.2612 - loss: 0.2612\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - huber_metric_1: 0.2328 - loss: 0.2328\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x18bef1865c0>"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train_scaled, y_train, epochs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'CompileMetrics' object has no attribute 'threshold'\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    model.metrics[-1].threshold\n",
        "except Exception as ex:\n",
        "    print(ex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "for metric in model.metrics:\n",
        "    if isinstance(metric, HuberMetric):\n",
        "        print(f\"Huber Metric threshold: {metric.threshold}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "it seems like keras has updated from HOML tutorial, i will investigate where to find our threshold..\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "keras.src.trainers.compile_utils.CompileMetrics"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(model.metrics[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['__annotations__',\n",
              " '__call__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_api_export_path',\n",
              " '_api_export_symbol_id',\n",
              " '_build_metrics_set',\n",
              " '_check_super_called',\n",
              " '_dtype',\n",
              " '_flat_metrics',\n",
              " '_flat_weighted_metrics',\n",
              " '_flatten_y',\n",
              " '_metrics',\n",
              " '_obj_type',\n",
              " '_tracker',\n",
              " '_unpickle_model',\n",
              " '_user_metrics',\n",
              " '_user_weighted_metrics',\n",
              " '_variables',\n",
              " 'add_variable',\n",
              " 'add_weight',\n",
              " 'build',\n",
              " 'built',\n",
              " 'dtype',\n",
              " 'from_config',\n",
              " 'get_config',\n",
              " 'metrics',\n",
              " 'name',\n",
              " 'output_names',\n",
              " 'reset_state',\n",
              " 'result',\n",
              " 'stateless_reset_state',\n",
              " 'stateless_result',\n",
              " 'stateless_update_state',\n",
              " 'update_state',\n",
              " 'variables']"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dir(model.metrics[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "__main__.HuberMetric"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(model.metrics[-1].metrics[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2.0"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.metrics[-1].metrics[0].threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "here it is :))))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Looks like it works fine! More simply, we could have created the class like this:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HuberMetric(tf.keras.metrics.Mean):\n",
        "    def __init__(self, threshold=1.0, name='HuberMetric', dtype=None):\n",
        "        self.threshold = threshold\n",
        "        self.huber_fn = create_huber(threshold)\n",
        "        super().__init__(name=name, dtype=dtype)\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        metric = self.huber_fn(y_true, y_pred)\n",
        "        super(HuberMetric, self).update_state(metric, sample_weight)\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"threshold\": self.threshold}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577us/step - HuberMetric: 1.0599 - loss: 0.5274\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - HuberMetric: 0.3215 - loss: 0.1598\n"
          ]
        }
      ],
      "source": [
        "tf.keras.utils.set_random_seed(42)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                          input_shape=input_shape),\n",
        "    tf.keras.layers.Dense(1),\n",
        "])\n",
        "\n",
        "model.compile(loss=tf.keras.losses.Huber(2.0), optimizer=\"nadam\",\n",
        "              weighted_metrics=[HuberMetric(2.0)])\n",
        "\n",
        "np.random.seed(42)\n",
        "sample_weight = np.random.rand(len(y_train))\n",
        "history = model.fit(X_train_scaled, y_train, epochs=2,\n",
        "                    sample_weight=sample_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.3256884217262268, 0.32568849524955656)"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(history.history[\"loss\"][0],\n",
        " history.history[\"HuberMetric\"][0] * sample_weight.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(\"saved_models/my_model_with_a_custom_metric_v2.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(\"saved_models/my_model_with_a_custom_metric_v2.keras\",\n",
        "                                   custom_objects={\"HuberMetric\": HuberMetric})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603us/step - HuberMetric: 0.2627 - loss: 0.2262\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - HuberMetric: 0.2298 - loss: 0.1999\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x18bf045e5f0>"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train_scaled, y_train, epochs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2.0"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.metrics[-1].metrics[-1].threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custom Layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "explayer = tf.keras.layers.Lambda(lambda x: tf.exp(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.36787945, 1.        , 2.7182817 ], dtype=float32)>"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "explayer(tf.constant([-1., 0., 1.]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "or with sub-classing api\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MyDense(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, activation=None, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.activation = tf.keras.activations.get(activation)\n",
        "\n",
        "    def build(self, batch_input_shape):\n",
        "        self.kernel = self.add_weight(\n",
        "            name=\"kernel\", shape=[batch_input_shape[-1], self.units],\n",
        "            initializer=\"he_normal\")\n",
        "        self.bias = self.add_weight(\n",
        "            name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
        "\n",
        "    def call(self, X):\n",
        "        return self.activation(X @ self.kernel + self.bias)\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"units\": self.units,\n",
        "                \"activation\": tf.keras.activations.serialize(self.activation)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\sayed\\AppData\\Local\\Temp\\ipykernel_14288\\3097604586.py:3: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 991us/step - loss: 5.7265 - val_loss: 6.9255\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - loss: 0.9550 - val_loss: 2.6011\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - loss: 0.7227\n"
          ]
        }
      ],
      "source": [
        "tf.keras.utils.set_random_seed(42)\n",
        "model = tf.keras.Sequential([\n",
        "    MyDense(30, activation=\"relu\", input_shape=input_shape),\n",
        "    MyDense(1)\n",
        "])\n",
        "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))\n",
        "model.evaluate(X_test_scaled, y_test)\n",
        "model.save(\"saved_models/my_model_with_a_custom_layer.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 914us/step - loss: 0.7034 - val_loss: 0.8613\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - loss: 0.5803 - val_loss: 0.4588\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x18bf27b5840>"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = tf.keras.models.load_model(\"saved_models/my_model_with_a_custom_layer.keras\",\n",
        "                                   custom_objects={\"MyDense\": MyDense})\n",
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MyMultiLayer(tf.keras.layers.Layer):\n",
        "    def call(self, X):\n",
        "        X1, X2 = X\n",
        "        return X1+X2, X1*X2, X1/X2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<KerasTensor shape=(None, 2), dtype=float32, sparse=False, name=keras_tensor_20>,\n",
              " <KerasTensor shape=(None, 2), dtype=float32, sparse=False, name=keras_tensor_21>,\n",
              " <KerasTensor shape=(None, 2), dtype=float32, sparse=False, name=keras_tensor_22>)"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs1 = tf.keras.layers.Input(shape=[2])\n",
        "inputs2 = tf.keras.layers.Input(shape=[2])\n",
        "MyMultiLayer()((inputs1, inputs2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              " array([[ 9., 18.],\n",
              "        [ 6., 10.]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              " array([[18., 72.],\n",
              "        [ 8., 21.]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              " array([[0.5      , 0.5      ],\n",
              "        [0.5      , 2.3333333]], dtype=float32)>)"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X1, X2 = np.array([[3., 6.], [2., 7.]]), np.array([[6., 12.], [4., 3.]])\n",
        "MyMultiLayer()((X1, X2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's create a layer with a different behavior during training and testing:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MyGaussianNoise(tf.keras.layers.Layer):\n",
        "    def __init__(self, stddev, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.stddev = stddev\n",
        "\n",
        "    def call(self, X, training=None):\n",
        "        if training:\n",
        "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
        "            return X + noise\n",
        "        return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\sayed\\AppData\\Local\\Temp\\ipykernel_14288\\1546716026.py:3: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 944us/step - loss: 2.7619 - val_loss: 25.1369\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - loss: 1.3951 - val_loss: 14.9793\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 1.1219\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1.1244221925735474"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.keras.utils.set_random_seed(42)\n",
        "model = tf.keras.Sequential([\n",
        "    MyGaussianNoise(stddev=1.0, input_shape=input_shape),\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\",\n",
        "                          kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))\n",
        "model.evaluate(X_test_scaled, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custom Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tf.keras.utils.register_keras_serializable()\n",
        "class ResidualBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, n_layers, n_units, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.n_layers = n_layers\n",
        "        self.n_units = n_units\n",
        "        self.hidden = [tf.keras.layers.Dense(\n",
        "            n_units, activation='relu', kernel_initializer=\"he_normal\")\n",
        "            for _ in range(n_layers)]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        Z = inputs\n",
        "        for layer in self.hidden:\n",
        "            Z = layer(Z)\n",
        "        return Z + inputs\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"n_layers\": self.n_layers,\n",
        "            \"n_units\": self.n_units,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class ResidualRegressor(tf.keras.models.Model):\n",
        "    def __init__(self, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.output_dim = output_dim\n",
        "        self.linear1 = tf.keras.layers.Dense(30)\n",
        "        self.rBlock1 = ResidualBlock(2, 30)\n",
        "        self.rBlock2 = ResidualBlock(2, 30)\n",
        "        self.out = tf.keras.layers.Dense(output_dim)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        Z = self.linear1(inputs)\n",
        "        for _ in range(1+3):\n",
        "            Z = self.rBlock1(Z)\n",
        "        Z = self.rBlock2(Z)\n",
        "        return self.out(Z)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 761us/step - loss: 38.7647\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 0.9498\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - loss: 0.5812\n",
            "Epoch 1/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 814us/step - loss: 0.6747\n",
            "Epoch 2/2\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - loss: 0.5269\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[1.0190629],\n",
              "       [1.8359567],\n",
              "       [4.045906 ]], dtype=float32)"
            ]
          },
          "execution_count": 148,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.keras.utils.set_random_seed(42)\n",
        "model = ResidualRegressor(1)\n",
        "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
        "history = model.fit(X_train_scaled, y_train, epochs=2)\n",
        "score = model.evaluate(X_test_scaled, y_test)\n",
        "model.save(\"saved_models/my_custom_model.keras\")\n",
        "\n",
        "model = tf.keras.models.load_model(\"saved_models/my_custom_model.keras\")\n",
        "history = model.fit(X_train_scaled, y_train, epochs=2)\n",
        "model.predict(X_test_scaled[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Losses and Metrics Based on Model Internals\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ReconstructingRegressor(tf.keras.Model):\n",
        "    def __init__(self, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.hidden = [tf.keras.layers.Dense(30, activation=\"relu\",\n",
        "                                             kernel_initializer=\"he_normal\")\n",
        "                       for _ in range(5)]\n",
        "        self.out = tf.keras.layers.Dense(output_dim)\n",
        "        self.reconstruction_mean = tf.keras.metrics.Mean(\n",
        "            name=\"reconstruction_error\")\n",
        "\n",
        "    def build(self, batch_input_shape):\n",
        "        n_inputs = batch_input_shape[-1]\n",
        "        self.reconstruct = tf.keras.layers.Dense(n_inputs)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        Z = inputs\n",
        "        for layer in self.hidden:\n",
        "            Z = layer(Z)\n",
        "        reconstruction = self.reconstruct(Z)\n",
        "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
        "        self.add_loss(0.05 * recon_loss)\n",
        "        if training:\n",
        "            result = self.reconstruction_mean(recon_loss)\n",
        "            self.add_metric(result)\n",
        "        return self.out(Z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "error due to changes in tf new version (add metric deleted)\n"
          ]
        }
      ],
      "source": [
        "tf.keras.utils.set_random_seed(42)\n",
        "try:\n",
        "    model = ReconstructingRegressor(1)\n",
        "    model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
        "    history = model.fit(X_train_scaled, y_train, epochs=5)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "except:\n",
        "    print('error due to changes in tf new version (add metric deleted)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Computing Gradients Using Autodiff\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
