{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 12 Exercises: Custom Models and Training with TensorFlow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How would you describe TensorFlow in a short sentence? What are its main features? Can you name other popular deep learning libraries?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow is a deep-learning large library ( framework ) that enable users to build and train models at high level.\n",
    "\n",
    "Its core is similar to NumPy, but it also features GPU support, support for distributed computing, computation graph analysis and optimization capabilities (with a portable graph format that allows you to train a TensorFlow model in one environment and run it in another), an optimization API based on reverse-mode autodiff, and several powerful APIs such as tf.keras, tf.data, tf.image, tf.signal, and more.\n",
    "\n",
    "Pytorch, jax are also deep learning libraries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  Is TensorFlow a drop-in replacement for NumPy? What are the main differences between the two?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not exactly the replacement because tensorflow provide more.\n",
    "\n",
    "Tensorflow work with tensors, which can be used by ( and specifically created to ) **GPUs** and numpy not.\n",
    "\n",
    "Tensorflow is huge framework that provide many high-level APIs those make the process of deeplearning so easy and you have not build every thing from scratch each time.\n",
    "\n",
    "some functions do not behave in exactly the same way (for example, tf.transpose() creates a transposed copy of a tensor, while NumPy's T attribute creates a transposed view, without actually copying any data). Lastly, NumPy arrays are mutable, while TensorFlow tensors are not (but you can use a tf.Variable if you need a mutable object).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Do you get the same result with tf.range(10) and tf.constant(np.arange(10))?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor 1 (tf.range(10)): tf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10,), dtype=int32)\n",
      "Tensor 2 (tf.constant(np.arange(10))): tf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10,), dtype=int32)\n",
      "\n",
      "Data type of Tensor 1: <dtype: 'int32'>\n",
      "Data type of Tensor 2: <dtype: 'int32'>\n",
      "\n",
      "The tensors have the same data type.\n",
      "\n",
      "Are the tensor values equal?: tf.Tensor(True, shape=(), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Create a tensor using tf.range\n",
    "tensor1 = tf.range(10)\n",
    "\n",
    "# Create a tensor using tf.constant and np.arange\n",
    "tensor2 = tf.constant(np.arange(10))\n",
    "\n",
    "# Print the tensors\n",
    "print(\"Tensor 1 (tf.range(10)):\", tensor1)\n",
    "print(\"Tensor 2 (tf.constant(np.arange(10))):\", tensor2)\n",
    "\n",
    "# Check the data types\n",
    "print(\"\\nData type of Tensor 1:\", tensor1.dtype)\n",
    "print(\"Data type of Tensor 2:\", tensor2.dtype)\n",
    "\n",
    "# Check if tensors are created differently\n",
    "if tensor1.dtype != tensor2.dtype:\n",
    "    print(\"\\nThe tensors are different in data type.\")\n",
    "else:\n",
    "    print(\"\\nThe tensors have the same data type.\")\n",
    "\n",
    "# Check if they are equal in value\n",
    "print(\"\\nAre the tensor values equal?:\", tf.reduce_all(tf.equal(tensor1, tensor2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So They are the same exactly, but author needs is to distinguish between default numpy dtypes which is in his version int64 and default tensorflow dtypes which is int32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Can you name six other data structures available in TensorFlow, beyond regular tensors?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sets represented as regular tensors, but tensorflow provides special function to manipulate it such as tf.sets\n",
    "\n",
    "Queues\n",
    "\n",
    "Strings used in nlp, also represented as regular tensors, but tensorflow provides special function to manipulate it such as tf.strings\n",
    "\n",
    "RaggedTensors which can bee seen as array of arrays, but all arrays (tensors) inside are variant in length\n",
    "\n",
    "SparseTensors Tensors those elements mostly zeros\n",
    "\n",
    "TensorArray is list of tensors but all has the same shape, and it can be fixed size or dynamic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. You can define a custom loss function by writing a function or by subclassing thetf.keras.losses.Loss class. When would you use each option?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when we want to create a loss function, we just implement it as regular python function.\n",
    "\n",
    "if our function accepts hyperparameter or any other state, then we should subclass `tf.keras.losses.Loss` and implement `__init__`, `call()` functions, and to the hyperparameter saved along with the model, we implement `get_config()` also.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.  Similarly, you can define a custom metric in a function or as a subclass of tf.keras.metrics.Metric. When would you use each option?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "similarly, we can define it in a function if it is so simple without hyperparameters or caching records needed (ex: recall). otherwise sub-classing would be must.\n",
    "\n",
    "Moreover, if computing the metric over a whole epoch is not equivalent to computing the mean metric over all batches in that epoch (e.g., as for the precision and recall metrics), then you should subclass the keras.metrics.Metric class and implement the `__init__()`, `update_state()`, and `result()` methods to keep track of a running metric during each epoch. You should also implement the `reset_states()` method unless all it needs to do is reset all variables to 0.0. If you want the state to be saved along with the model, then you should implement the `get_config()` method as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.  When should you create a custom layer versus a custom model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Custom Model created when it is not sequential and has multi inputs, multi outputs.\n",
    "\n",
    "The Custom Layer created when we need another behavior of the built-in layers, and we put it in the custom or sequential model easily.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.  What are some use cases that require writing your own custom training loop?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "usually we will not write our custom training loop. except in debugging or using different optimizer ot different parts of the network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.  Can custom Keras components contain arbitrary Python code, or must they be convertible to TF functions?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you absolutely need to include arbitrary Python code in a custom component, you can either wrap it in a tf.`py_function()` operation (but this will reduce performance and limit your model's portability) or set `dynamic=True `when creating the custom layer or model (or set `run_eagerly=True` when calling the model's `compile()` method).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. What are the main rules to respect if you want a function to be convertible to a TF function?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a function may not be convertible to tf function ( cannot used by @tf.function at graph execution ) for this reasons:\n",
    "if the function contains python prints or it modifying dynamic python things like list, dictionaries. or use global variables\n",
    "\n",
    "unsupported operations by tf\n",
    "\n",
    "dynamic flow control by python like using loops or if.\n",
    "\n",
    "has type Inconsistencies, the graph expects all tensors to be the same type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. When would you need to create a dynamic Keras model? How do you do that? Why not make all your models dynamic?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dynamic Keras model can be useful for debugging, as it will not compile any custom component to a TF Function, and you can use any Python debugger to debug your code. It can also be useful if you want to include arbitrary Python code in your model (or in your training code), including calls to external libraries. To make a model dynamic, you must set dynamic=True when creating it. Alternatively, you can set run_eagerly=True when calling the model's compile() method. Making a model dynamic prevents Keras from using any of TensorFlow's graph features, so it will slow down training and inference, and you will not have the possibility to export the computation graph, which will limit your model's portability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
