{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#  Chapter 16: Natural Language Processing with RNNs and Attention","metadata":{"id":"ggVICmR_lDmx"}},{"cell_type":"code","source":"import os\nos.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\" \n\nimport tensorflow as tf\nimport numpy as np\nfrom pathlib import Path\nimport tf_keras","metadata":{"id":"kGPHeBvwlDmz","trusted":true,"execution":{"iopub.status.busy":"2025-01-17T14:38:39.349438Z","iopub.execute_input":"2025-01-17T14:38:39.349751Z","iopub.status.idle":"2025-01-17T14:38:46.836225Z","shell.execute_reply.started":"2025-01-17T14:38:39.349705Z","shell.execute_reply":"2025-01-17T14:38:46.835527Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"\nshakespeare_url = \"https://homl.info/shakespeare\"  # shortcut URL\nfilepath = tf.keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\nwith open(filepath) as f:\n    shakespeare_text = f.read()","metadata":{"id":"IIdD6DJIlDm0","outputId":"688cc633-fb31-4ef3-c339-0097afcff21e","trusted":true,"execution":{"iopub.status.busy":"2025-01-17T14:38:46.837238Z","iopub.execute_input":"2025-01-17T14:38:46.837748Z","iopub.status.idle":"2025-01-17T14:38:48.101445Z","shell.execute_reply.started":"2025-01-17T14:38:46.837705Z","shell.execute_reply":"2025-01-17T14:38:48.100623Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://homl.info/shakespeare\n1115394/1115394 [==============================] - 0s 0us/step\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"print(shakespeare_text[:80])","metadata":{"id":"D6bLc0i3nwns","outputId":"ab6e1b8e-72b3-48ba-807c-8aa00921e9f2","trusted":true,"execution":{"iopub.status.busy":"2025-01-17T14:38:48.102901Z","iopub.execute_input":"2025-01-17T14:38:48.103154Z","iopub.status.idle":"2025-01-17T14:38:48.106736Z","shell.execute_reply.started":"2025-01-17T14:38:48.103133Z","shell.execute_reply":"2025-01-17T14:38:48.105864Z"}},"outputs":[{"name":"stdout","text":"First Citizen:\nBefore we proceed any further, hear me speak.\n\nAll:\nSpeak, speak.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"all_chars  = \"\".join(sorted(set(shakespeare_text.lower())))\nprint(all_chars)\nprint(len(all_chars))","metadata":{"id":"uN6lMOKSn-ex","outputId":"c934481e-1d9c-44ba-f4e9-b56f5e25063e","trusted":true,"execution":{"iopub.status.busy":"2025-01-17T14:38:48.108137Z","iopub.execute_input":"2025-01-17T14:38:48.108363Z","iopub.status.idle":"2025-01-17T14:38:48.141555Z","shell.execute_reply.started":"2025-01-17T14:38:48.108345Z","shell.execute_reply":"2025-01-17T14:38:48.140786Z"}},"outputs":[{"name":"stdout","text":"\n !$&',-.3:;?abcdefghijklmnopqrstuvwxyz\n39\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## Generating Shakespearean Text Using a Character RNN","metadata":{"id":"R7JKQcEOoTZa"}},{"cell_type":"markdown","source":"### Preparing Dataset for a char level rnn model","metadata":{"id":"yNXX2EUpomcj"}},{"cell_type":"markdown","source":"#### Text Vectorization","metadata":{"id":"VsEzAzNpoQ2X"}},{"cell_type":"code","source":"text_vec_layer = tf.keras.layers.TextVectorization(split='character', standardize='lower')\ntext_vec_layer.adapt([shakespeare_text])\nencoded = text_vec_layer([shakespeare_text])[0]\nencoded","metadata":{"id":"IwRa58oQoJqV","outputId":"814a5d49-050b-42c6-94b5-cf2738617efc","trusted":true,"execution":{"iopub.status.busy":"2025-01-17T14:38:48.142329Z","iopub.execute_input":"2025-01-17T14:38:48.142618Z","iopub.status.idle":"2025-01-17T14:38:50.852088Z","shell.execute_reply.started":"2025-01-17T14:38:48.142588Z","shell.execute_reply":"2025-01-17T14:38:50.851114Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([21,  7, 10, ..., 22, 28, 12])>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"encoded -= 2 # drop 0 for padding and 1 for unkown tokens\nn_tokens = text_vec_layer.vocabulary_size()-2\ndataset_size = len(encoded)\nprint(\"n_tokens:\", n_tokens)\nprint(\"dataset_size:\", dataset_size)","metadata":{"id":"22HqryeMo9m-","outputId":"b74e3a9c-4cd4-4646-b226-3955d2f841d4","trusted":true,"execution":{"iopub.status.busy":"2025-01-17T14:38:50.853037Z","iopub.execute_input":"2025-01-17T14:38:50.853379Z","iopub.status.idle":"2025-01-17T14:38:50.861608Z","shell.execute_reply.started":"2025-01-17T14:38:50.853347Z","shell.execute_reply":"2025-01-17T14:38:50.860936Z"}},"outputs":[{"name":"stdout","text":"n_tokens: 39\ndataset_size: 1115394\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"it is seq2seq model","metadata":{"id":"b_y5WRc6p2NB"}},{"cell_type":"code","source":"def to_dataset(sequence, length, shuffle=False, seed=None, batch_size=32):\n    dataset = tf.data.Dataset.from_tensor_slices(sequence)\n    dataset = dataset.window(length+1, shift=1, drop_remainder =True)\n    dataset = dataset.flat_map(lambda window: window.batch(length+1))\n    if shuffle:\n      dataset = dataset.shuffle(buffer_size=100_000, seed=seed)\n    dataset = dataset.batch(batch_size)\n    return dataset.map(lambda window: (window[:,:-1], window[:,1:])).prefetch(1)","metadata":{"id":"IV4ry7kspnTt","trusted":true,"execution":{"iopub.status.busy":"2025-01-17T14:38:50.862430Z","iopub.execute_input":"2025-01-17T14:38:50.862780Z","iopub.status.idle":"2025-01-17T14:38:50.877617Z","shell.execute_reply.started":"2025-01-17T14:38:50.862745Z","shell.execute_reply":"2025-01-17T14:38:50.876852Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# There's just one sample in this dataset: the input represents \"to b\" and the\n# output represents \"o be\"\nlist(to_dataset(text_vec_layer([\"To be\"])[0], length=4))","metadata":{"id":"Bx0wgQbEvrXh","trusted":true,"execution":{"iopub.status.busy":"2025-01-17T14:38:50.879367Z","iopub.execute_input":"2025-01-17T14:38:50.879639Z","iopub.status.idle":"2025-01-17T14:38:50.979403Z","shell.execute_reply.started":"2025-01-17T14:38:50.879604Z","shell.execute_reply":"2025-01-17T14:38:50.978643Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"[(<tf.Tensor: shape=(1, 4), dtype=int64, numpy=array([[ 4,  5,  2, 23]])>,\n  <tf.Tensor: shape=(1, 4), dtype=int64, numpy=array([[ 5,  2, 23,  3]])>)]"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"length = 100\ntf.random.set_seed(42)\n\ntrain_set = to_dataset(encoded[:1_000_000], length=100, shuffle=True, seed=42)\nvalid_set = to_dataset(encoded[1_000_000:1_060_000], length=100)\ntest_set = to_dataset(encoded[1_060_000:], length=100)\n","metadata":{"id":"QXiSTEIlrMy4","trusted":true,"execution":{"iopub.status.busy":"2025-01-17T14:38:50.980210Z","iopub.execute_input":"2025-01-17T14:38:50.980427Z","iopub.status.idle":"2025-01-17T14:38:51.495431Z","shell.execute_reply.started":"2025-01-17T14:38:50.980409Z","shell.execute_reply":"2025-01-17T14:38:51.494788Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"### Building and Training the Char-RNN Model\n","metadata":{"id":"gk63mwP6r4-c"}},{"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16),\n    tf.keras.layers.GRU(128, return_sequences=True),\n    tf.keras.layers.Dense(n_tokens, activation='softmax'),\n])\n\n\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='nadam',\n              metrics=['accuracy'])\n\nmodel_ckpt = tf.keras.callbacks.ModelCheckpoint(\n \"my_shakespeare_model.keras\", monitor=\"val_accuracy\", save_best_only=True)","metadata":{"id":"kY2pmL0JrvaP","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T17:37:19.212960Z","iopub.execute_input":"2024-12-30T17:37:19.213201Z","iopub.status.idle":"2024-12-30T17:37:19.583128Z","shell.execute_reply.started":"2024-12-30T17:37:19.213181Z","shell.execute_reply":"2024-12-30T17:37:19.582213Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.summary()","metadata":{"id":"X6bVn23_u1BF","outputId":"94714040-f6d2-4cd2-e803-0a2d349fe2f6","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T17:37:19.583973Z","iopub.execute_input":"2024-12-30T17:37:19.584274Z","iopub.status.idle":"2024-12-30T17:37:19.602784Z","shell.execute_reply.started":"2024-12-30T17:37:19.584238Z","shell.execute_reply":"2024-12-30T17:37:19.601963Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(train_set, validation_data=valid_set, epochs=1,\n callbacks=[model_ckpt])\n","metadata":{"id":"sRLAF770uRUs","outputId":"bda73fdd-b3a4-4192-9828-aa3af0f02100","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T17:37:19.603725Z","iopub.execute_input":"2024-12-30T17:37:19.604002Z","iopub.status.idle":"2024-12-30T17:42:04.888880Z","shell.execute_reply.started":"2024-12-30T17:37:19.603976Z","shell.execute_reply":"2024-12-30T17:42:04.888056Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### shakespeare model","metadata":{"id":"KJ9F9K3zubMQ"}},{"cell_type":"code","source":"shakespeare_model = tf.keras.Sequential([\n    text_vec_layer,\n    tf.keras.layers.Lambda(lambda X:X-2),\n    model\n])","metadata":{"id":"zsJbgOituYIJ","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T17:42:04.889683Z","iopub.execute_input":"2024-12-30T17:42:04.889895Z","iopub.status.idle":"2024-12-30T17:42:05.108865Z","shell.execute_reply.started":"2024-12-30T17:42:04.889874Z","shell.execute_reply":"2024-12-30T17:42:05.108150Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# or we can the pretrained model\nurl = \"https://github.com/ageron/data/raw/main/shakespeare_model.tgz\"\npath = tf.keras.utils.get_file(\"shakespeare_model.tgz\", url, extract=True)\nmodel_path = Path(path).with_name(\"shakespeare_model\")\nshakespeare_model = tf.keras.models.load_model(model_path)","metadata":{"id":"9lowGE-YxtwJ","outputId":"6171cba6-800a-40ba-bcbf-356f0a552ed2","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T17:42:05.109709Z","iopub.execute_input":"2024-12-30T17:42:05.110013Z","iopub.status.idle":"2024-12-30T17:42:07.704277Z","shell.execute_reply.started":"2024-12-30T17:42:05.109980Z","shell.execute_reply":"2024-12-30T17:42:07.703643Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_path","metadata":{"id":"xshpDtK20oEF","outputId":"f3d36e88-420d-436c-bf96-bc6e401cf2d2","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T17:42:07.713655Z","iopub.execute_input":"2024-12-30T17:42:07.713995Z","iopub.status.idle":"2024-12-30T17:42:07.719110Z","shell.execute_reply.started":"2024-12-30T17:42:07.713964Z","shell.execute_reply":"2024-12-30T17:42:07.718271Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"shakespeare_model.summary()","metadata":{"id":"0zUAgHRFuxl5","outputId":"e67d4541-e9d2-4ed8-a969-3461342b5824","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T17:42:07.719932Z","iopub.execute_input":"2024-12-30T17:42:07.720207Z","iopub.status.idle":"2024-12-30T17:42:07.749346Z","shell.execute_reply.started":"2024-12-30T17:42:07.720185Z","shell.execute_reply":"2024-12-30T17:42:07.748737Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"predicting next character:","metadata":{"id":"D84edM0eu8M_"}},{"cell_type":"code","source":"y_propas = shakespeare_model.predict(['To be or not to b'])[0]\nprint( y_propas[-1].shape,'\\n\\n', y_propas[-1],'\\n')\npredicted_char = tf.argmax(y_propas[-1])\nprint(predicted_char+2) # predicted character index + 2 to map the original char again\n\nprint(\"predicted character is: \", text_vec_layer.get_vocabulary()[predicted_char+2])","metadata":{"id":"SDkWyotsuxih","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T17:42:07.750080Z","iopub.execute_input":"2024-12-30T17:42:07.750341Z","iopub.status.idle":"2024-12-30T17:42:08.196723Z","shell.execute_reply.started":"2024-12-30T17:42:07.750313Z","shell.execute_reply":"2024-12-30T17:42:08.196027Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Generating Shakespear 'FAKE' text","metadata":{}},{"cell_type":"markdown","source":"Instead of using greedy decoding (predict next character and add it to the current text and use all to predict next char and so on.)\n\nThe previous approach lead to repeated words.\n\nWe can use random sampling (with keeping the estimated propabilty of the model prediction when sampling)\n","metadata":{}},{"cell_type":"code","source":"tf.random.set_seed(412)\n\nlog_propas = tf.math.log([[.5,.4,.1]]) # simulate the logits\nprint(\"> logits: \", log_propas)\n\nprint(\"> Sampling results: \", tf.random.categorical(log_propas, num_samples=8))","metadata":{"id":"7HEbXQd_uxcn","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T17:42:08.198654Z","iopub.execute_input":"2024-12-30T17:42:08.198891Z","iopub.status.idle":"2024-12-30T17:42:08.324829Z","shell.execute_reply.started":"2024-12-30T17:42:08.198871Z","shell.execute_reply":"2024-12-30T17:42:08.323920Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tf.random.categorical(log_propas, num_samples=1).numpy()[0,0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T17:42:08.326160Z","iopub.execute_input":"2024-12-30T17:42:08.326525Z","iopub.status.idle":"2024-12-30T17:42:08.332960Z","shell.execute_reply.started":"2024-12-30T17:42:08.326494Z","shell.execute_reply":"2024-12-30T17:42:08.332224Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"we can take the control over the generated diversity of the text using `temperature`\n\n> high values indicates creativity\n> \n> low values indicates precision","metadata":{}},{"cell_type":"code","source":"def next_char(text, temperature=1):\n    y_propas = shakespeare_model.predict([text], verbose=0)[0,-1:]\n    y_propas = tf.math.log(y_propas) / temperature\n    predicted_ind = tf.random.categorical(y_propas, num_samples=1).numpy()[0,0]\n    return text_vec_layer.get_vocabulary()[predicted_ind+2]\n\ndef generate(text, n_char=50, temperature=1):\n    for _ in range(n_char):\n        text += next_char(text, temperature)\n    return text\n","metadata":{"id":"AAJY317euww4","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T17:42:08.333687Z","iopub.execute_input":"2024-12-30T17:42:08.333930Z","iopub.status.idle":"2024-12-30T17:42:08.345952Z","shell.execute_reply.started":"2024-12-30T17:42:08.333910Z","shell.execute_reply":"2024-12-30T17:42:08.345080Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tf.random.set_seed(42)\nprint(generate('to be or not to b', temperature=0.01),end= '\\n'+'='*50+'\\n')\nprint(generate('to be or not to b', temperature=1),end= '\\n'+'='*50+'\\n')\nprint(generate('to be or not to b', temperature=199),end= '\\n'+'='*50+'\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T17:42:08.346770Z","iopub.execute_input":"2024-12-30T17:42:08.347050Z","iopub.status.idle":"2024-12-30T17:42:18.716411Z","shell.execute_reply.started":"2024-12-30T17:42:08.347016Z","shell.execute_reply":"2024-12-30T17:42:18.715467Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Sampling from top k charcters","metadata":{}},{"cell_type":"code","source":"def next_char(text, model, text_vec_layer, k=5, temperature=1.0):\n    y_probs = model.predict([text], verbose=0)[0, -1:]\n    y_probs = tf.math.log(y_probs) / temperature\n    top_k_indices = tf.math.top_k(y_probs, k=k).indices\n    top_k_probs = tf.gather(y_probs, top_k_indices, axis=-1)\n    top_k_probs = tf.reshape(top_k_probs, (1, -1))\n    predicted_idx = tf.random.categorical(top_k_probs, num_samples=1)[0, 0]\n    char_idx = top_k_indices[0].numpy()[predicted_idx]+2\n    return text_vec_layer.get_vocabulary()[char_idx]\n\ndef generate(text, model, text_vec_layer, n_chars=50, k=5, temperature=1.0):\n    generated_text = text\n    for _ in range(n_chars):\n        generated_text += next_char(generated_text, model, text_vec_layer, k, temperature)\n    return generated_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T17:42:18.717382Z","iopub.execute_input":"2024-12-30T17:42:18.717736Z","iopub.status.idle":"2024-12-30T17:42:18.723589Z","shell.execute_reply.started":"2024-12-30T17:42:18.717701Z","shell.execute_reply":"2024-12-30T17:42:18.722785Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tf.random.set_seed(42)\ngenerated_text = generate(\"To be or not to b\", shakespeare_model, text_vec_layer, n_chars=100, k=5, temperature=0.7)\nprint(generated_text)\nprint('-'*60,'\\n\\n')\n\ngenerated_text = generate(\"To be or not to b\", shakespeare_model, text_vec_layer, n_chars=100, k=5, temperature=0.001)\nprint(generated_text)\nprint('-'*60,'\\n\\n')\n\ngenerated_text = generate(\"To be or not to b\", shakespeare_model, text_vec_layer, n_chars=100, k=5, temperature=60)\nprint(generated_text)\nprint('-'*60,'\\n\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T17:42:18.724459Z","iopub.execute_input":"2024-12-30T17:42:18.724736Z","iopub.status.idle":"2024-12-30T17:42:40.214153Z","shell.execute_reply.started":"2024-12-30T17:42:18.724704Z","shell.execute_reply":"2024-12-30T17:42:40.213363Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Nucleus Sampling and Beam Search Generation","metadata":{}},{"cell_type":"code","source":"def generate_beam_search(text, max_length=50, beam_width=3, temperature=1.0):\n    beams = [(0.0, text)]\n    completed_beams = []\n    \n    for _ in range(max_length):\n        candidates = []\n        for score, beam_text in beams:\n            y_probs = shakespeare_model.predict([beam_text], verbose=0)[0, -1:]\n            logits = tf.math.log(y_probs) / temperature\n            top_k_logits, top_k_indices = tf.math.top_k(logits, k=beam_width)\n            \n            for logit, token_idx in zip(top_k_logits[0], top_k_indices[0]):\n                next_char = text_vec_layer.get_vocabulary()[token_idx.numpy() + 2]\n                new_text = beam_text + next_char\n                new_score = score - float(logit)\n                candidates.append((new_score, new_text))\n        \n        beams = sorted(candidates, key=lambda x: x[0])[:beam_width] # cut off top candidates after each generation step.\n    \n    return beams[0][1]\n\ndef generate_nucleus(text, max_length=50, p=0.9, temperature=1.0):\n    result = text\n    \n    for _ in range(max_length):\n        y_probs = shakespeare_model.predict([result], verbose=0)[0, -1:]\n        logits = tf.math.log(y_probs) / temperature\n        probs = tf.nn.softmax(logits, axis=-1)[0]\n        sorted_indices = tf.argsort(probs, direction='DESCENDING')\n        sorted_probs = tf.gather(probs, sorted_indices)\n        cumulative_probs = tf.cumsum(sorted_probs)\n        nucleus_mask = cumulative_probs <= p\n        filtered_probs = sorted_probs * tf.cast(nucleus_mask, tf.float32)\n        filtered_probs = filtered_probs / tf.reduce_sum(filtered_probs)\n        sample_idx = tf.random.categorical(tf.math.log(filtered_probs[None, :]), num_samples=1)[0, 0]\n        char_idx = sorted_indices[sample_idx]\n        next_char = text_vec_layer.get_vocabulary()[char_idx.numpy() + 2]\n        result += next_char\n    \n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T17:59:12.862042Z","iopub.execute_input":"2024-12-30T17:59:12.862348Z","iopub.status.idle":"2024-12-30T17:59:12.870995Z","shell.execute_reply.started":"2024-12-30T17:59:12.862325Z","shell.execute_reply":"2024-12-30T17:59:12.869997Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"-------------------Beam Search (conservative)-------------------\")\nprint(generate_beam_search(\"to be or not to b\", max_length=50, beam_width=3, temperature=0.7))\nprint(\"=\"*64)\n\nprint(\"\\n---------------------Beam Search (standard)---------------------\")\nprint(generate_beam_search(\"to be or not to b\", max_length=50, beam_width=5, temperature=1.0))\nprint(\"=\"*64)\n\nprint(\"\\n-------------------Nucleus Sampling (focused)-------------------\")\nprint(generate_nucleus(\"to be or not to b\", max_length=50, p=0.9, temperature=0.7))\nprint(\"=\"*64)\n\nprint(\"\\n-------------------Nucleus Sampling (creative)------------------\")\nprint(generate_nucleus(\"to be or not to b\", max_length=50, p=0.95, temperature=1.3))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T18:00:30.033536Z","iopub.execute_input":"2024-12-30T18:00:30.033873Z","iopub.status.idle":"2024-12-30T18:01:06.348556Z","shell.execute_reply.started":"2024-12-30T18:00:30.033844Z","shell.execute_reply":"2024-12-30T18:01:06.347781Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"###  Stateful RNN","metadata":{}},{"cell_type":"markdown","source":"Preparing the dataset for statefull rnn, it must takes sequential and non-overlaping dataset rather than shuffled and overlapped dataset for stateless rnn.","metadata":{}},{"cell_type":"code","source":"def to_dataset_for_stateful_rnn(sequence, length):\n    ds = tf.data.Dataset.from_tensor_slices(sequence)\n    ds = ds.window(length+1, shift = length, drop_remainder=True)\n    ds = ds.flat_map(lambda window: window.batch(length+1)).batch(1)\n    return ds.map(lambda window: (window[:,:-1], window[:,1:])).prefetch(1)\n\nstateful_train_set = to_dataset_for_stateful_rnn(encoded[:1_000_000], length)\nstateful_valid_set = to_dataset_for_stateful_rnn(encoded[1_000_000:1_060_000],length)\nstateful_test_set = to_dataset_for_stateful_rnn(encoded[1_060_000:], length)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T18:23:29.088867Z","iopub.execute_input":"2024-12-30T18:23:29.089146Z","iopub.status.idle":"2024-12-30T18:23:29.189206Z","shell.execute_reply.started":"2024-12-30T18:23:29.089126Z","shell.execute_reply":"2024-12-30T18:23:29.188338Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Using Batching with Statful RNN","metadata":{}},{"cell_type":"code","source":"def to_non_overlapping_windows(sequence, length):\n    ds = tf.data.Dataset.from_tensor_slices(sequence)\n    ds = ds.window(length + 1, shift=length, drop_remainder=True)\n    return ds.flat_map(lambda window: window.batch(length + 1))\n\ndef to_batched_dataset_for_stateful_rnn(sequence, length, batch_size=32):\n    parts = np.array_split(sequence, batch_size)\n    datasets = tuple(to_non_overlapping_windows(part, length) for part in parts) \n    ds = tf.data.Dataset.zip(datasets).map(lambda *windows: tf.stack(windows))\n    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)\n\nstateful_train_set = to_batched_dataset_for_stateful_rnn(encoded[:1_000_000], length)\nstateful_valid_set = to_batched_dataset_for_stateful_rnn(encoded[1_000_000:1_060_000],length)\nstateful_test_set = to_batched_dataset_for_stateful_rnn(encoded[1_060_000:], length)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T18:40:04.153342Z","iopub.execute_input":"2024-12-30T18:40:04.153681Z","iopub.status.idle":"2024-12-30T18:40:05.059115Z","shell.execute_reply.started":"2024-12-30T18:40:04.153656Z","shell.execute_reply":"2024-12-30T18:40:05.058494Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for idx, (seq, tar) in enumerate(to_batched_dataset_for_stateful_rnn(tf.range(50), length=3, batch_size=4)):\n    print('Sequence: \\n', seq, '\\nTarget: \\n', tar, '\\n\\n')\n    if idx>0: break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T18:42:04.726802Z","iopub.execute_input":"2024-12-30T18:42:04.727125Z","iopub.status.idle":"2024-12-30T18:42:04.825656Z","shell.execute_reply.started":"2024-12-30T18:42:04.727098Z","shell.execute_reply":"2024-12-30T18:42:04.824789Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Building the stateful model","metadata":{}},{"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16,\n                              batch_input_shape=[32, None]),\n    tf.keras.layers.GRU(128, return_sequences=True, stateful=True),\n    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n])\n\nclass ResetStatesCallback(tf.keras.callbacks.Callback):\n    def on_epoch_begin(self, epoch, logs):\n        self.model.reset_states()\n\nmodel_ckpt = tf.keras.callbacks.ModelCheckpoint(\n    \"my_stateful_shakespeare_model.keras\",\n    monitor=\"val_accuracy\",\n    save_best_only=True)\n\nmodel.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n              metrics=[\"accuracy\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T18:48:55.845338Z","iopub.execute_input":"2024-12-30T18:48:55.845705Z","iopub.status.idle":"2024-12-30T18:48:56.064028Z","shell.execute_reply.started":"2024-12-30T18:48:55.845676Z","shell.execute_reply":"2024-12-30T18:48:56.063161Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(stateful_train_set, validation_data=stateful_valid_set,\n                    epochs=20, callbacks=[ResetStatesCallback(), model_ckpt])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T18:48:56.120265Z","iopub.execute_input":"2024-12-30T18:48:56.120498Z","iopub.status.idle":"2024-12-30T18:50:18.505923Z","shell.execute_reply.started":"2024-12-30T18:48:56.120477Z","shell.execute_reply":"2024-12-30T18:50:18.505266Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"To use the model with different batch sizes, we need to create a stateless copy:\n","metadata":{}},{"cell_type":"code","source":"stateless_model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16),\n    tf.keras.layers.GRU(128, return_sequences=True),\n    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n])\n\nstateless_model.build(tf.TensorShape([None, None]))\nstateless_model.set_weights(model.get_weights())\n\nshakespeare_model = tf.keras.Sequential([\n    text_vec_layer,\n    tf.keras.layers.Lambda(lambda X: X - 2),  # no <PAD> or <UNK> tokens\n    stateless_model\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T18:54:00.435844Z","iopub.execute_input":"2024-12-30T18:54:00.436158Z","iopub.status.idle":"2024-12-30T18:54:00.915894Z","shell.execute_reply.started":"2024-12-30T18:54:00.436135Z","shell.execute_reply":"2024-12-30T18:54:00.914908Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"generated_text = generate(\"To be or not to b\", shakespeare_model, text_vec_layer, n_chars=100, k=5, temperature=0.001)\nprint(generated_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T18:54:03.283624Z","iopub.execute_input":"2024-12-30T18:54:03.283923Z","iopub.status.idle":"2024-12-30T18:54:10.503201Z","shell.execute_reply.started":"2024-12-30T18:54:03.283900Z","shell.execute_reply":"2024-12-30T18:54:10.502471Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Sentiment Analysis","metadata":{}},{"cell_type":"markdown","source":"let's download the `imdb` dataset from tensorflow datasets","metadata":{}},{"cell_type":"code","source":"import tensorflow_datasets as tfds\n\nraw_train_set, raw_valid_set, raw_test_set = tfds.load('imdb_reviews', \n                                       split=['train[:90%]', 'train[90%:]', 'test'],\n                                       as_supervised=True)\ntf.random.set_seed(42)\ntrain_set = raw_train_set.shuffle(5000, seed=42).batch(32).prefetch(1)\nvalid_set = raw_valid_set.batch(32).prefetch(1)\ntest_set = raw_test_set.batch(32).prefetch(1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T14:41:17.245973Z","iopub.execute_input":"2025-01-17T14:41:17.246283Z","iopub.status.idle":"2025-01-17T14:41:50.808730Z","shell.execute_reply.started":"2025-01-17T14:41:17.246260Z","shell.execute_reply":"2025-01-17T14:41:50.808002Z"}},"outputs":[{"name":"stdout","text":"Downloading and preparing dataset 80.23 MiB (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Dl Completed...: 0 url [00:00, ? url/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"218c0a5a8fb04853910dc86802a1b1cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Dl Size...: 0 MiB [00:00, ? MiB/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51ee53f574024e51b224aafb10363961"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train examples...:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Shuffling /root/tensorflow_datasets/imdb_reviews/plain_text/incomplete.J4R1P2_1.0.0/imdb_reviews-train.tfrecor…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test examples...:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Shuffling /root/tensorflow_datasets/imdb_reviews/plain_text/incomplete.J4R1P2_1.0.0/imdb_reviews-test.tfrecord…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating unsupervised examples...:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Shuffling /root/tensorflow_datasets/imdb_reviews/plain_text/incomplete.J4R1P2_1.0.0/imdb_reviews-unsupervised.…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset imdb_reviews downloaded and prepared to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"for review, label in raw_train_set.take(4):\n    print(\">> \",review.numpy().decode('utf-8')[:100])\n    print(\"Label: \", label.numpy())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T14:41:50.809695Z","iopub.execute_input":"2025-01-17T14:41:50.810023Z","iopub.status.idle":"2025-01-17T14:41:50.865767Z","shell.execute_reply.started":"2025-01-17T14:41:50.810000Z","shell.execute_reply":"2025-01-17T14:41:50.864922Z"}},"outputs":[{"name":"stdout","text":">>  This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. \nLabel:  0\n>>  I have been known to fall asleep during films, but this is usually due to a combination of things in\nLabel:  0\n>>  Mann photographs the Alberta Rocky Mountains in a superb fashion, and Jimmy Stewart and Walter Brenn\nLabel:  0\n>>  This is the kind of film for a snowy Sunday afternoon when the rest of the world can go ahead with i\nLabel:  1\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"#### sentiment analysis model","metadata":{}},{"cell_type":"code","source":"vocab_size = 1000\ntext_vec_layer = tf.keras.layers.TextVectorization(max_tokens=vocab_size)\ntext_vec_layer.adapt(train_set.map(lambda review, label: review))\n\nembed_size =128\ntf.random.set_seed(42)\nmodel = tf.keras.Sequential([\n    text_vec_layer,\n    tf.keras.layers.Embedding(input_dim = vocab_size, output_dim=128),\n    tf.keras.layers.GRU(128),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T14:41:50.867430Z","iopub.execute_input":"2025-01-17T14:41:50.867668Z","iopub.status.idle":"2025-01-17T14:41:54.350932Z","shell.execute_reply.started":"2025-01-17T14:41:50.867649Z","shell.execute_reply":"2025-01-17T14:41:54.349931Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"for review, label in raw_train_set.take(1):\n    print(text_vec_layer(review.numpy().decode('utf-8')))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T14:41:54.352003Z","iopub.execute_input":"2025-01-17T14:41:54.352215Z","iopub.status.idle":"2025-01-17T14:41:54.436084Z","shell.execute_reply.started":"2025-01-17T14:41:54.352195Z","shell.execute_reply":"2025-01-17T14:41:54.435210Z"}},"outputs":[{"name":"stdout","text":"tf.Tensor(\n[ 11  14  34 410 383  18  90  28   1   8  33   1   1  41 491   1 192  24\n  86 152  19  11 218 315  28  65 241 217   8 487  54  65  86 113  95  22\n   1  11  93 644 729  11  18   7  34 396   1 171   1 404   2  88   1 137\n  67 144  52   2   1   1  67 245  65   1  16   1   1   1   1   1   1   3\n  40   1   1  17   1  14 158  19   4   1 874   1   8   4  18  12  14   1\n   5  98 146   1  10 237 688  12  48  24  93  39  11   1 152  39   1   1\n  50 403  10  95   1 863 140   9], shape=(116,), dtype=int64)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"note that tekens 0,1 are for unknown and padding","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T14:41:54.437092Z","iopub.execute_input":"2025-01-17T14:41:54.437426Z","iopub.status.idle":"2025-01-17T14:41:54.456672Z","shell.execute_reply.started":"2025-01-17T14:41:54.437393Z","shell.execute_reply":"2025-01-17T14:41:54.456026Z"}},"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n text_vectorization_1 (Text  (None, None)              0         \n Vectorization)                                                  \n                                                                 \n embedding (Embedding)       (None, None, 128)         128000    \n                                                                 \n gru (GRU)                   (None, 128)               99072     \n                                                                 \n dense (Dense)               (None, 1)                 129       \n                                                                 \n=================================================================\nTotal params: 227201 (887.50 KB)\nTrainable params: 227201 (887.50 KB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\nhistory1 = model.fit(train_set, validation_data=valid_set, epochs=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T14:41:54.457601Z","iopub.execute_input":"2025-01-17T14:41:54.457901Z","iopub.status.idle":"2025-01-17T14:43:10.244667Z","shell.execute_reply.started":"2025-01-17T14:41:54.457872Z","shell.execute_reply":"2025-01-17T14:43:10.243543Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n704/704 [==============================] - 39s 52ms/step - loss: 0.6934 - accuracy: 0.5035 - val_loss: 0.6931 - val_accuracy: 0.5016\nEpoch 2/5\n704/704 [==============================] - 30s 42ms/step - loss: 0.6927 - accuracy: 0.5039 - val_loss: 0.6936 - val_accuracy: 0.4988\nEpoch 3/5\n157/704 [=====>........................] - ETA: 22s - loss: 0.6921 - accuracy: 0.5054","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-342ec27bcc6a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1802\u001b[0m                         ):\n\u001b[1;32m   1803\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1804\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1805\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1806\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    870\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":20},{"cell_type":"markdown","source":"we notice that the model performance is very poor and this is because there's many padding tokens in the seqeuences fed to the model. which make the RNN forget about what it learned.","metadata":{}},{"cell_type":"markdown","source":"<details>\n<summary><h3>RNNs and Padding Issues Illustration (click for details)</h3></summary>\n\nLet’s break this down step by step with a simple RNN example. We’ll demonstrate how zeros (padding tokens) lead to forgetting or losing information in the sequence `\"What a goal, wow.\"`.\n\n### Initial Setup\n- **Input Sequence**: `\"What a goal, wow.\"`\n- After padding: `[\"What\", \"a\", \"goal,\", \"wow.\", 0, 0, 0, ..., 0]`\n- Assume each token is represented as an embedding vector for the RNN:\n  ```plaintext\n  [\"What\" → [1, 0.5],\n   \"a\" → [0.2, 0.1],\n   \"goal,\" → [0.9, 0.7],\n   \"wow.\" → [1.2, 0.8],\n   0 → [0, 0],  # Padding token mapped to [0, 0]\n   0 → [0, 0], ..., 0 → [0, 0]]\n  ```\n\n### RNN Computation\nFor simplicity, assume:\n- Hidden state size = 2\n- Initial hidden state: `h_0 = [0, 0]`\n- Weight matrices: `W_x`, `W_h`, and bias `b` (omitted explicit values for clarity)\n\nThe RNN computes at each timestep:\n\\[\nh_t = \\tanh(W_x \\cdot x_t + W_h \\cdot h_{t-1} + b)\n\\]\n\n#### Step-by-Step\n1. **First Token: `\"What\"`**\n   - \\( x_1 = [1, 0.5] \\)\n   - \\( h_1 = \\tanh(W_x \\cdot [1, 0.5] + W_h \\cdot [0, 0] + b) \\)\n   - Result: \\( h_1 = [0.8, 0.6] \\) (example value)\n\n2. **Second Token: `\"a\"`**\n   - \\( x_2 = [0.2, 0.1] \\)\n   - \\( h_2 = \\tanh(W_x \\cdot [0.2, 0.1] + W_h \\cdot [0.8, 0.6] + b) \\)\n   - Result: \\( h_2 = [0.7, 0.5] \\)\n\n3. **After `\"goal,\"** and `\"wow.\"**\n   - Gradually builds up meaningful context:\n     - \\( h_3 = [0.9, 0.7] \\), \\( h_4 = [1.0, 0.8] \\)\n\n4. **Padding Tokens: `0`**\n   - \\( x_5 = [0, 0] \\), \\( x_6 = [0, 0] \\), etc.\n   - For these, \\( h_t = \\tanh(W_x \\cdot [0, 0] + W_h \\cdot h_{t-1} + b) \\).\n   - Since \\( x_t = [0, 0] \\), only \\( W_h \\cdot h_{t-1} \\) contributes. However, over multiple padding steps, the hidden state \\( h_t \\) starts to decay:\n     - \\( h_5 \\approx [0.6, 0.4] \\)\n     - \\( h_6 \\approx [0.3, 0.2] \\)\n     - Eventually, \\( h_t \\approx [0, 0] \\).\n\n### Key Observations\n- **Information Loss**: The meaningful context \\( h_4 = [1.0, 0.8] \\) (derived from `\"What a goal, wow.\"`) decays to near-zero as padding dominates.\n- **Learning Challenges**: During training, the RNN might learn to ignore later timesteps entirely, assuming they don’t contain useful information.\n\n</details>","metadata":{}},{"cell_type":"markdown","source":"We can use a mask to ignore zeros during computation and training. This helps the RNN focus only on the meaningful parts of the sequence.\nThis is done by setting `mask_zero` equal to true in the embedding layer, and it propagates the mask downstream to all layers that accept it.","metadata":{}},{"cell_type":"code","source":"model = tf.keras.Sequential([\n    text_vec_layer,\n    tf.keras.layers.Embedding(input_dim = vocab_size, output_dim=128, mask_zero=True),\n    tf.keras.layers.GRU(128),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n\n])\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\nhistory2 = model.fit(train_set, validation_data=valid_set, epochs=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T14:43:18.051006Z","iopub.execute_input":"2025-01-17T14:43:18.051340Z","iopub.status.idle":"2025-01-17T14:45:21.143301Z","shell.execute_reply.started":"2025-01-17T14:43:18.051314Z","shell.execute_reply":"2025-01-17T14:45:21.142567Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n704/704 [==============================] - 34s 43ms/step - loss: 0.5662 - accuracy: 0.6919 - val_loss: 0.4344 - val_accuracy: 0.8080\nEpoch 2/5\n704/704 [==============================] - 22s 32ms/step - loss: 0.3900 - accuracy: 0.8325 - val_loss: 0.3341 - val_accuracy: 0.8544\nEpoch 3/5\n704/704 [==============================] - 22s 31ms/step - loss: 0.3134 - accuracy: 0.8711 - val_loss: 0.3113 - val_accuracy: 0.8680\nEpoch 4/5\n704/704 [==============================] - 22s 31ms/step - loss: 0.2817 - accuracy: 0.8848 - val_loss: 0.3148 - val_accuracy: 0.8616\nEpoch 5/5\n704/704 [==============================] - 22s 31ms/step - loss: 0.2603 - accuracy: 0.8953 - val_loss: 0.3168 - val_accuracy: 0.8664\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"The model now is capable to learn and performing well!","metadata":{}},{"cell_type":"markdown","source":"<details>\n<summary><h3>Why is masking needed in internal layers, and how does padding affect the input layer?</h3></summary>\n\n### Question:\n**Why do we need masking in the internal layers (not just the first one), and how does padding zeros only in the input layer affect the sequence processing?**\n\n### Answer:\n1. Propagation of Padding Effect\nEven though the first layer (e.g., an embedding or RNN) processes the padded input and replaces explicit zeros with meaningful values (e.g., the previous timestep's hidden state), those padding steps still represent \"invalid\" parts of the sequence.\nWithout a mask, internal layers may treat these invalid timesteps as meaningful, which can corrupt the learned representations.\nFor example:\n\nSuppose the input sequence is [word1, word2, 0, 0], and the RNN replaces the padding steps with the hidden state of word2.\nIf an internal RNN or dense layer operates on these outputs without masking, it may treat the repeated values from word2 as meaningful information, skewing the results.\n\n</details>","metadata":{}},{"cell_type":"code","source":"tf.random.set_seed(42)\ninputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\ntoken_ids = text_vec_layer(inputs)\nmask = tf.math.not_equal(token_ids,0)\nZ = tf.keras.layers.Embedding(input_dim = vocab_size, output_dim=128)(token_ids)\nZ = tf.keras.layers.GRU(128, dropout=.2)(Z, mask=mask)\noutputs = tf.keras.layers.Dense(1, activation='sigmoid')(Z)\nmodel = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\",\n              metrics=[\"accuracy\"])\nhistory3 = model.fit(train_set, validation_data=valid_set, epochs=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T20:37:41.435364Z","iopub.execute_input":"2025-01-02T20:37:41.435698Z","iopub.status.idle":"2025-01-02T20:39:50.309697Z","shell.execute_reply.started":"2025-01-02T20:37:41.435669Z","shell.execute_reply":"2025-01-02T20:39:50.308741Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Last approach using ragged tensors","metadata":{}},{"cell_type":"code","source":"text_vec_layer_ragged = tf.keras.layers.TextVectorization(max_tokens=vocab_size, ragged=True)\ntext_vec_layer_ragged.adapt(train_set.map(lambda review, label: review))\ntext_vec_layer_ragged([\"Great movie!\", \"This is DiCaprio's best role.\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T21:38:46.951654Z","iopub.execute_input":"2025-01-02T21:38:46.951946Z","iopub.status.idle":"2025-01-02T21:38:49.661941Z","shell.execute_reply.started":"2025-01-02T21:38:46.951925Z","shell.execute_reply":"2025-01-02T21:38:49.661241Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"text_vec_layer([\"Great movie!\", \"This is DiCaprio's best role.\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T21:38:49.662900Z","iopub.execute_input":"2025-01-02T21:38:49.663214Z","iopub.status.idle":"2025-01-02T21:38:49.676423Z","shell.execute_reply.started":"2025-01-02T21:38:49.663190Z","shell.execute_reply":"2025-01-02T21:38:49.675521Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"embed_size = 128\ntf.random.set_seed(42)\nmodel = tf.keras.Sequential([\n    text_vec_layer_ragged,\n    tf.keras.layers.Embedding(vocab_size, embed_size),\n    tf.keras.layers.GRU(128),\n    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n])\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\",\n              metrics=[\"accuracy\"])\nhistory4 = model.fit(train_set, validation_data=valid_set, epochs=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T20:40:16.760579Z","iopub.execute_input":"2025-01-02T20:40:16.760895Z","iopub.status.idle":"2025-01-02T20:42:27.885279Z","shell.execute_reply.started":"2025-01-02T20:40:16.760869Z","shell.execute_reply":"2025-01-02T20:42:27.884570Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Using TensorBoard for Embedding Visualization","metadata":{}},{"cell_type":"code","source":"embed_size = 128\ntf.random.set_seed(42)\nmodel = tf.keras.Sequential([\n    text_vec_layer_ragged,\n    tf.keras.layers.Embedding(vocab_size, embed_size),\n    tf.keras.layers.GRU(128),\n    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n])\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\",\n              metrics=[\"accuracy\"])\n\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T21:38:52.873980Z","iopub.execute_input":"2025-01-02T21:38:52.874344Z","iopub.status.idle":"2025-01-02T21:38:53.152697Z","shell.execute_reply.started":"2025-01-02T21:38:52.874313Z","shell.execute_reply":"2025-01-02T21:38:53.151782Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nvocab = text_vec_layer_ragged.get_vocabulary()\n\n# Create a metadata file for your words\nmetadata_file = \"metadata.tsv\"\nwith open(metadata_file, 'w') as f:\n    for word in vocab:\n        f.write(f\"{word}\\n\")\n\ntensorboard_callback = tf.keras.callbacks.TensorBoard(\n    log_dir=\"./logs\",\n    embeddings_freq=1,\n    embeddings_layer_names=['embedding'], \n    embeddings_metadata=metadata_file,\n    update_freq='epoch'\n)\n\n\nhistory5 = model.fit(\n    train_set,  \n    validation_data=valid_set,  \n    epochs=5,\n    callbacks=[tensorboard_callback]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T21:39:09.995549Z","iopub.execute_input":"2025-01-02T21:39:09.995891Z","iopub.status.idle":"2025-01-02T21:41:25.833572Z","shell.execute_reply.started":"2025-01-02T21:39:09.995868Z","shell.execute_reply":"2025-01-02T21:41:25.832839Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  Reusing Pretrained Embeddings and Language Models\n","metadata":{}},{"cell_type":"code","source":"import os\nimport tensorflow_hub as hub\n\nos.environ['TFHUB_CACHE_DIR'] = \"my_tfhub_cache\"\ntf.random.set_seed(42)\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n                   trainable=True, dtype=tf.string, input_shape=[]),\n    tf.keras.layers.Dense(64, activation=\"relu\"),\n    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T14:46:54.257915Z","iopub.execute_input":"2025-01-17T14:46:54.258226Z","iopub.status.idle":"2025-01-17T14:47:00.314746Z","shell.execute_reply.started":"2025-01-17T14:46:54.258199Z","shell.execute_reply":"2025-01-17T14:47:00.314037Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\",\n              metrics=[\"accuracy\"])\nhistory_with_pretrained = model.fit(train_set,\n                                    validation_data=valid_set, epochs=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T14:47:08.967218Z","iopub.execute_input":"2025-01-17T14:47:08.967529Z","iopub.status.idle":"2025-01-17T15:13:17.936638Z","shell.execute_reply.started":"2025-01-17T14:47:08.967504Z","shell.execute_reply":"2025-01-17T15:13:17.935686Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n704/704 [==============================] - 757s 1s/step - loss: 0.2936 - accuracy: 0.8758 - val_loss: 0.2487 - val_accuracy: 0.8972\nEpoch 2/10\n704/704 [==============================] - 149s 211ms/step - loss: 0.0253 - accuracy: 0.9925 - val_loss: 0.2877 - val_accuracy: 0.9016\nEpoch 3/10\n704/704 [==============================] - 114s 162ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.3840 - val_accuracy: 0.8952\nEpoch 4/10\n704/704 [==============================] - 86s 123ms/step - loss: 5.5912e-04 - accuracy: 1.0000 - val_loss: 0.4240 - val_accuracy: 0.8944\nEpoch 5/10\n704/704 [==============================] - 78s 111ms/step - loss: 5.0484e-04 - accuracy: 1.0000 - val_loss: 0.4320 - val_accuracy: 0.8968\nEpoch 6/10\n704/704 [==============================] - 80s 113ms/step - loss: 3.8763e-04 - accuracy: 1.0000 - val_loss: 0.4859 - val_accuracy: 0.8992\nEpoch 7/10\n704/704 [==============================] - 82s 116ms/step - loss: 2.7927e-05 - accuracy: 1.0000 - val_loss: 0.5297 - val_accuracy: 0.8984\nEpoch 8/10\n704/704 [==============================] - 79s 112ms/step - loss: 1.5812e-05 - accuracy: 1.0000 - val_loss: 0.5565 - val_accuracy: 0.8988\nEpoch 9/10\n704/704 [==============================] - 72s 102ms/step - loss: 9.7672e-06 - accuracy: 1.0000 - val_loss: 0.5808 - val_accuracy: 0.8984\nEpoch 10/10\n704/704 [==============================] - 72s 102ms/step - loss: 6.2828e-06 - accuracy: 1.0000 - val_loss: 0.6036 - val_accuracy: 0.8976\n","output_type":"stream"}],"execution_count":24}]}